{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Design\n",
    "\n",
    "Knowledge gap between public and specialists and uncertainties are an important factors that drive pandemic anxiety, in this task, we will examine papers that discuss some of the controversial topics that contribute to rumours and anxiety\n",
    "\n",
    "Here I develop a search system to extract sentences from abstracts that are relevant to a question. The questions are associated with rumour and uncertain information circulating in the public. We can try different questions in here, and an important part is to evaluate the search system with human annotation baseline if we want to push forward this work as a paper. \n",
    "\n",
    "Step 1:\n",
    "The search system first extract abstract contains a keyword (e.g. ‘mask’), then we use LDA to group the abstract topics. We identify a topic that is  most relevant to the question and we extract abstracts that contain the target topic. The system sentences that contain the keyword from the relevant abstracts. The standard apporach of a search system is to used TFIDF to rank documents, here we use LDA topic modeling on nouns, verbs and adjectives of the abstract. Users can decide the relevant information when they know what are the most frequent keywords in each topic.\n",
    "\n",
    "The benefit of this approach is that when we want to know the relevant content for a question, we don't know what are the keywords in the article are more relevant to the question we ask, because the users are usually not farmiliar with academic papers. In our system, the topic keywords serve as prime for the query in the next step for extracting sentences in the abstract.\n",
    "\n",
    "Step 2:\n",
    "We manually annotate the key sentences to identify information in these key sentences. \n",
    "\n",
    "Keywords:\n",
    "Incubation period, asymptomatic, mask, death rate, paracetamone\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search System "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from collections import defaultdict\n",
    "import string\n",
    "from gensim.models import CoherenceModel\n",
    "import gensim\n",
    "from pprint import pprint\n",
    "import spacy,en_core_web_sm\n",
    "from nltk.stem import PorterStemmer\n",
    "import os\n",
    "import json\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "import re\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read metadata into dictionary format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaData:\n",
    "    def __init__(self):\n",
    "        \"\"\"Define varibles.\"\"\"\n",
    "        # path and data\n",
    "        self.path = '/afs/inf.ed.ac.uk/user/s16/s1690903/share/cov19_2/'\n",
    "        self.meta_data = pd.read_csv(self.path + 'metadata.csv')\n",
    "\n",
    "    def data_dict(self):\n",
    "        \"\"\"Convert df to dictionary. \"\"\"\n",
    "        mydict = lambda: defaultdict(mydict)\n",
    "        meta_data_dict = mydict()\n",
    "\n",
    "        for cord_uid, abstract, title, sha in zip(self.meta_data['cord_uid'], self.meta_data['abstract'], self.meta_data['title'], self.meta_data['sha']):\n",
    "            meta_data_dict[cord_uid]['title'] = title\n",
    "            meta_data_dict[cord_uid]['abstract'] = abstract\n",
    "            meta_data_dict[cord_uid]['sha'] = sha\n",
    "\n",
    "        return meta_data_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract documents contain keywords, preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractText:\n",
    "    \"\"\"Extract text according to keywords or phrases\"\"\"\n",
    "\n",
    "    def __init__(self, metaDict, keyword, variable):\n",
    "        \"\"\"Define varibles.\"\"\"\n",
    "        self.path = '/afs/inf.ed.ac.uk/user/s16/s1690903/share/cov19_2/'\n",
    "        self.metadata = metaDict\n",
    "        self.keyword = keyword\n",
    "        self.variable = variable\n",
    "\n",
    "\n",
    "    def simple_preprocess(self):\n",
    "        \"\"\"Simple text process: lower case, remove punc. \"\"\"\n",
    "        mydict = lambda: defaultdict(mydict)\n",
    "        cleaned = mydict()\n",
    "        for k, v in self.metadata.items():\n",
    "            sent = v[self.variable]\n",
    "            sent = str(sent).lower().translate(str.maketrans('', '', string.punctuation))\n",
    "            cleaned[k]['processed_text'] = sent\n",
    "            cleaned[k]['sha'] = v['sha']\n",
    "            cleaned[k]['title'] = v['title']\n",
    "\n",
    "        return cleaned\n",
    "\n",
    "    def very_simple_preprocess(self):\n",
    "        \"\"\"Simple text process: lower case only. \"\"\"\n",
    "        mydict = lambda: defaultdict(mydict)\n",
    "        cleaned = mydict()\n",
    "        for k, v in self.metadata.items():\n",
    "            sent = v[self.variable]\n",
    "            sent = str(sent).lower()\n",
    "            cleaned[k]['processed_text'] = sent\n",
    "            cleaned[k]['sha'] = v['sha']\n",
    "            cleaned[k]['title'] = v['title']\n",
    "\n",
    "        return cleaned\n",
    "     \n",
    "\n",
    "    def extract_w_keywords(self):\n",
    "        \"\"\"Select content with keywords.\"\"\"\n",
    "        mydict = lambda: defaultdict(mydict)\n",
    "        selected = mydict()\n",
    "        textdict = self.simple_preprocess()\n",
    "        for k, v in textdict.items():\n",
    "            if self.keyword in v['processed_text'].split():\n",
    "                #print(v['sha'])\n",
    "                selected[k]['processed_text'] = v['processed_text']\n",
    "                selected[k]['sha'] = v['sha']\n",
    "                selected[k]['title'] = v['title']\n",
    "        return selected\n",
    "\n",
    "    def extract_w_keywords_punc(self):\n",
    "        \"\"\"Select content with keywords, with punctuations in text\"\"\"\n",
    "        mydict = lambda: defaultdict(mydict)\n",
    "        selected = mydict()\n",
    "        textdict = self.very_simple_preprocess()\n",
    "        for k, v in textdict.items():\n",
    "            if self.keyword in v['processed_text'].split():\n",
    "                    #print(v['sha'])\n",
    "                selected[k]['processed_text'] = v['processed_text']\n",
    "                selected[k]['sha'] = v['sha']\n",
    "                selected[k]['title'] = v['title']\n",
    "        return selected\n",
    "\n",
    "    def get_noun_verb(self, text):\n",
    "        \"\"\"get noun trunks for the lda model,\n",
    "        change noun and verb part to decide what\n",
    "        you want to use as input for LDA\"\"\"\n",
    "        ps = PorterStemmer()\n",
    "      \n",
    "        #find nound trunks\n",
    "        nlp = en_core_web_sm.load()\n",
    "        all_extracted = {}\n",
    "        for k, v in text.items():\n",
    "            #v = v.replace('incubation period', 'incubation_period')\n",
    "            doc = nlp(v)\n",
    "            nouns = ' '.join(str(v) for v in doc if v.pos_ is 'NOUN').split()\n",
    "            verbs = ' '.join(ps.stem(str(v)) for v in doc if v.pos_ is 'VERB').split()\n",
    "            adj = ' '.join(str(v) for v in doc if v.pos_ is 'ADJ').split()\n",
    "            all_w = nouns + verbs + adj\n",
    "            all_extracted[k] = all_w\n",
    "      \n",
    "        return all_extracted\n",
    "\n",
    "    def get_noun_verb2(self, text):\n",
    "        \"\"\"get noun trunks for the lda model,\n",
    "        change noun and verb part to decide what\n",
    "        you want to use as input for LDA\"\"\"\n",
    "        ps = PorterStemmer()\n",
    "      \n",
    "        #find nound trunks\n",
    "        nlp = en_core_web_sm.load()\n",
    "        all_extracted = {}\n",
    "        for k, v in text.items():\n",
    "            #v = v.replace('incubation period', 'incubation_period')\n",
    "            doc = nlp(v['processed_text'])\n",
    "            nouns = ' '.join(ps.stem(str(v)) for v in doc if v.pos_ is 'NOUN').split()\n",
    "            verbs = ' '.join(ps.stem(str(v)) for v in doc if v.pos_ is 'VERB').split()\n",
    "            adj = ' '.join(str(v) for v in doc if v.pos_ is 'ADJ').split()\n",
    "            all_w = nouns + verbs + adj\n",
    "            all_extracted[k] = all_w\n",
    "      \n",
    "        return all_extracted\n",
    "\n",
    "    def tokenization(self, text):\n",
    "        \"\"\"get noun trunks for the lda model,\n",
    "        change noun and verb part to decide what\n",
    "        you want to use as input for the next step\"\"\"\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "        all_extracted = {}\n",
    "        for k, v in text.items():\n",
    "            doc = nlp(v)\n",
    "            all_extracted[k] = [w.text for w in doc]\n",
    "      \n",
    "        return all_extracted\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using LDA to rank documents\n",
    "LDA is optimized by coherence score u_mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDATopic:\n",
    "    def __init__(self, processed_text, topic_num, alpha, eta):\n",
    "        \"\"\"Define varibles.\"\"\"\n",
    "        self.path = '/afs/inf.ed.ac.uk/user/s16/s1690903/share/cov19_2/'\n",
    "        self.text = processed_text\n",
    "        self.topic_num = topic_num\n",
    "        self.alpha = alpha\n",
    "        self.eta = eta\n",
    "\n",
    "    def get_lda_score_eval(self, dictionary, bow_corpus):\n",
    "        \"\"\"LDA model and coherence score.\"\"\"\n",
    "\n",
    "        lda_model = gensim.models.ldamodel.LdaModel(bow_corpus, num_topics=self.topic_num, id2word=dictionary, passes=10,  update_every=1, random_state = 300, alpha=self.alpha, eta=self.eta)\n",
    "        #pprint(lda_model.print_topics())\n",
    "\n",
    "        # get coherence score\n",
    "        cm = CoherenceModel(model=lda_model, corpus=bow_corpus, coherence='u_mass')\n",
    "        coherence = cm.get_coherence()\n",
    "        print('coherence score is {}'.format(coherence))\n",
    "\n",
    "        return lda_model, coherence\n",
    "\n",
    "    def get_score_dict(self, bow_corpus, lda_model_object):\n",
    "        \"\"\"\n",
    "        get lda score for each document\n",
    "        \"\"\"\n",
    "        all_lda_score = {}\n",
    "        for i in range(len(bow_corpus)):\n",
    "            lda_score ={}\n",
    "            for index, score in sorted(lda_model_object[bow_corpus[i]], key=lambda tup: -1*tup[1]):\n",
    "                lda_score[index] = score\n",
    "                od = collections.OrderedDict(sorted(lda_score.items()))\n",
    "            all_lda_score[i] = od\n",
    "        return all_lda_score\n",
    "\n",
    "\n",
    "    def topic_modeling(self):\n",
    "        \"\"\"Get LDA topic modeling.\"\"\"\n",
    "        # generate dictionary\n",
    "        dictionary = gensim.corpora.Dictionary(self.text.values())\n",
    "        bow_corpus = [dictionary.doc2bow(doc) for doc in self.text.values()]\n",
    "        # modeling\n",
    "        model, coherence = self.get_lda_score_eval(dictionary, bow_corpus)\n",
    "\n",
    "        lda_score_all = self.get_score_dict(bow_corpus, model)\n",
    "\n",
    "        all_lda_score_df = pd.DataFrame.from_dict(lda_score_all)\n",
    "        all_lda_score_dfT = all_lda_score_df.T\n",
    "        all_lda_score_dfT = all_lda_score_dfT.fillna(0)\n",
    "\n",
    "        return model, coherence, all_lda_score_dfT\n",
    "\n",
    "    def get_ids_from_selected(self, text):\n",
    "        \"\"\"Get unique id from text \"\"\"\n",
    "        id_l = []\n",
    "        for k, v in text.items():\n",
    "            id_l.append(k)\n",
    "            \n",
    "        return id_l\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select document (abstract/ article body) according to search result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatchArticleBody:\n",
    "    def __init__(self, path, selected_id):\n",
    "        \"\"\"Define varibles.\"\"\"\n",
    "        self.path = path\n",
    "        self.selected_id = selected_id\n",
    "\n",
    "\n",
    "    def read_folder(self):\n",
    "        \"\"\"\n",
    "        Creates a nested dictionary that represents the folder structure of rootdir\n",
    "        \"\"\"\n",
    "        rootdir = self.path.rstrip(os.sep)\n",
    "\n",
    "        article_dict = {}\n",
    "        for path, dirs, files in os.walk(rootdir):\n",
    "            for f in files:\n",
    "                file_id = f.split('.')[0]\n",
    "                #print(file_id)\n",
    "                try:\n",
    "                # load json file according to id\n",
    "                    with open(self.path + f) as f:\n",
    "                        data = json.load(f)\n",
    "                except:\n",
    "                    pass\n",
    "                article_dict[file_id] = data\n",
    "\n",
    "        return article_dict\n",
    "\n",
    "\n",
    "    def extract_bodytext(self):\n",
    "        \"\"\"Unpack nested dictionary and extract body of the article\"\"\"\n",
    "        body = {}\n",
    "        article_dict = self.read_folder()\n",
    "        for k, v in article_dict.items():\n",
    "            strings = ''\n",
    "            prevString = ''\n",
    "            for entry in v['body_text']:\n",
    "                strings = strings + prevString\n",
    "                prevString = entry['text']\n",
    "\n",
    "            body[k] = strings\n",
    "        return body\n",
    "\n",
    "\n",
    "    def get_title_by_bodykv(self, article_dict, keyword):\n",
    "        \"\"\"Search keyword in article body and return title\"\"\"\n",
    "\n",
    "        article_dict = self.read_folder()\n",
    "        selected_id = self.extract_id_list()\n",
    "\n",
    "        result = {}\n",
    "        for k, v in article_dict.items():\n",
    "            for entry in v['body_text']:\n",
    "                if (keyword in entry['text'].split()) and (k in selected_id):\n",
    "                    result[k] = v['metadata']['title']\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "    def extract_id_list(self):\n",
    "        \"\"\"Extract ids from the selected text. \"\"\"\n",
    "        selected_id = []\n",
    "        for k, v in self.selected_id.items():\n",
    "            selected_id.append(str(v['sha']).split(';')[0])\n",
    "            try:\n",
    "                selected_id.append(str(v['sha']).split(';')[1])\n",
    "                selected_id.append(str(v['sha']).split(';')[2])\n",
    "                selected_id.append(str(v['sha']).split(';')[3])\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        return selected_id\n",
    "\n",
    "\n",
    "    def select_text_w_id(self):\n",
    "        body_text = self.extract_bodytext()\n",
    "        selected_id = self.extract_id_list()\n",
    "        selected_text = {}\n",
    "        for k, v in body_text.items():\n",
    "            if k in selected_id:\n",
    "                selected_text[k] = v\n",
    "        return selected_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we extract articles contain the most relevant topic\n",
    "\n",
    "def selected_best_LDA(keyword, varname):\n",
    "        \"\"\"Select the best lda model with extracted text \"\"\"\n",
    "        # convert data to dictionary format\n",
    "        m = MetaData()\n",
    "        metaDict = m.data_dict()\n",
    "\n",
    "        #process text and extract text with keywords\n",
    "        et = ExtractText(metaDict, keyword, varname)\n",
    "        text1 = et.extract_w_keywords()\n",
    "\n",
    "\n",
    "        # extract nouns, verbs and adjetives\n",
    "        text = et.get_noun_verb2(text1)\n",
    "\n",
    "        # optimized alpha and beta\n",
    "        alpha = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "        beta = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "        mydict = lambda: defaultdict(mydict)\n",
    "        cohere_dict = mydict()\n",
    "        for a in alpha:\n",
    "            for b in beta:\n",
    "                lda = LDATopic(text, 20, a, b)\n",
    "                model, coherence, scores = lda.topic_modeling()\n",
    "                cohere_dict[coherence]['a'] = a\n",
    "                cohere_dict[coherence]['b'] = b\n",
    "    \n",
    "        # sort result dictionary to identify the best a, b\n",
    "        # select a,b with the largest coherence score \n",
    "        sort = sorted(cohere_dict.keys())[0] \n",
    "        a = cohere_dict[sort]['a']\n",
    "        b = cohere_dict[sort]['b']\n",
    "        \n",
    "        # run LDA with the optimized values\n",
    "        lda = LDATopic(text, 20, a, b)\n",
    "        model, coherence, scores_best = lda.topic_modeling()\n",
    "        pprint(model.print_topics())\n",
    "\n",
    "        # select merge ids with the LDA topic scores\n",
    "        id_l = lda.get_ids_from_selected(text)\n",
    "        scores_best['cord_uid'] = id_l\n",
    "\n",
    "        return scores_best\n",
    "\n",
    "\n",
    "\n",
    "def select_text_from_LDA_results(keyword, varname, scores_best, topic_num):\n",
    "        # choose papers with the most relevant topic\n",
    "        # convert data to dictionary format\n",
    "        m = MetaData()\n",
    "        metaDict = m.data_dict()\n",
    "\n",
    "        # process text and extract text with keywords\n",
    "        et = ExtractText(metaDict, keyword, varname)\n",
    "        # extract text together with punctuation\n",
    "        text1 = et.extract_w_keywords_punc()\n",
    "        # need to decide which topic to choose after training\n",
    "        sel = scores_best[scores_best[topic_num] > 0] \n",
    "        \n",
    "\n",
    "        mydict = lambda: defaultdict(mydict)\n",
    "        selected = mydict()\n",
    "        for k, v in text1.items():\n",
    "            if k in sel.cord_uid.tolist():\n",
    "                selected[k]['title'] = v['title']\n",
    "                selected[k]['processed_text'] = v['processed_text']\n",
    "                selected[k]['sha'] = v['sha']\n",
    "\n",
    "        return selected\n",
    "\n",
    "def extract_relevant_sentences(cor_dict, search_keywords):\n",
    "    \"\"\"Extract sentences contain keyword in relevant articles. \"\"\"\n",
    "\n",
    "    mydict = lambda: defaultdict(mydict)\n",
    "    sel_sentence = mydict()\n",
    "    \n",
    "    for k, v in cor_dict.items():\n",
    "        keyword_sentence = []\n",
    "        sentences = v['processed_text'].split('.')\n",
    "        for sentence in sentences:\n",
    "            # for each sentence, check if keyword exist\n",
    "            # append sentences contain keyword to list\n",
    "            keyword_sum = sum(1 for word in search_keywords if word in sentence)\n",
    "            if keyword_sum > 0:\n",
    "                keyword_sentence.append(sentence)         \n",
    "\n",
    "        # store results\n",
    "        if not keyword_sentence:\n",
    "            pass\n",
    "        else:\n",
    "            sel_sentence[k]['sentences'] = keyword_sentence\n",
    "            sel_sentence[k]['sha'] = v['sha']\n",
    "            sel_sentence[k]['title'] = v['title']\n",
    "    print('{} articles are relevant to the topic you choose'.format(len(sel_sentence)))\n",
    "\n",
    "    path = '/afs/inf.ed.ac.uk/user/s16/s1690903/share/cov19_2/'\n",
    "    df = pd.DataFrame.from_dict(sel_sentence, orient='index')\n",
    "    df.to_csv(path + 'search_results_{}.csv'.format(search_keywords))\n",
    "    sel_sentence_df = pd.read_csv(path + 'search_results_{}.csv'.format(search_keywords))\n",
    "    return sel_sentence, sel_sentence_df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Is wearing mask an effective way to control pandemic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coherence score is -4.336722639525242\n",
      "coherence score is -3.9010410239440367\n",
      "coherence score is -4.389157036678158\n",
      "coherence score is -4.585109650895275\n",
      "coherence score is -4.658858479495897\n",
      "coherence score is -4.181983373771045\n",
      "coherence score is -3.8225572164182773\n",
      "coherence score is -4.115948791902841\n",
      "coherence score is -4.405996653207033\n",
      "coherence score is -4.893575872869723\n",
      "coherence score is -3.763406611071013\n",
      "coherence score is -4.054636612549744\n",
      "coherence score is -3.974976478023649\n",
      "coherence score is -3.605098511028769\n",
      "coherence score is -3.218469889363284\n",
      "coherence score is -3.922771443759005\n",
      "coherence score is -4.56961216145051\n",
      "coherence score is -2.9539869626024027\n",
      "coherence score is -3.2776086868166603\n",
      "coherence score is -3.6310570980589993\n",
      "coherence score is -3.8129640801122164\n",
      "coherence score is -3.7657510362336026\n",
      "coherence score is -3.4720471247415454\n",
      "coherence score is -3.0704332896336615\n",
      "coherence score is -2.990024667297296\n",
      "coherence score is -4.893575872869723\n",
      "[(0,\n",
      "  '0.012*\"patient\" + 0.009*\"use\" + 0.009*\"recommend\" + 0.008*\"mask\" + '\n",
      "  '0.007*\"ventil\" + 0.006*\"acute\" + 0.005*\"respiratory\" + 0.004*\"failur\" + '\n",
      "  '0.004*\"niv\" + 0.003*\"intub\"'),\n",
      " (1,\n",
      "  '0.010*\"mask\" + 0.007*\"public\" + 0.007*\"infect\" + 0.006*\"use\" + 0.006*\"wear\" '\n",
      "  '+ 0.005*\"studi\" + 0.005*\"measur\" + 0.005*\"face\" + 0.005*\"behavior\" + '\n",
      "  '0.005*\"health\"'),\n",
      " (2,\n",
      "  '0.004*\"particl\" + 0.003*\"valu\" + 0.003*\"penetr\" + 0.003*\"size\" + '\n",
      "  '0.003*\"filter\" + 0.002*\"mask\" + 0.002*\"leak\" + 0.002*\"gauz\" + 0.002*\"model\" '\n",
      "  '+ 0.002*\"method\"'),\n",
      " (3,\n",
      "  '0.003*\"epitop\" + 0.002*\"protect\" + 0.002*\"vaccin\" + 0.002*\"skin\" + '\n",
      "  '0.001*\"immunogen\" + 0.001*\"neutral\" + 0.001*\"membran\" + 0.001*\"mucous\" + '\n",
      "  '0.001*\"design\" + 0.001*\"immune\"'),\n",
      " (4,\n",
      "  '0.004*\"viral\" + 0.003*\"psychological\" + 0.003*\"citi\" + 0.002*\"data\" + '\n",
      "  '0.002*\"such\" + 0.002*\"human\" + 0.002*\"impact\" + 0.002*\"virus\" + '\n",
      "  '0.002*\"sampl\" + 0.002*\"anxieti\"'),\n",
      " (5,\n",
      "  '0.011*\"mask\" + 0.008*\"air\" + 0.007*\"exhal\" + 0.006*\"cough\" + 0.005*\"oxygen\" '\n",
      "  '+ 0.005*\"smoke\" + 0.005*\"dispers\" + 0.004*\"patient\" + 0.004*\"leakag\" + '\n",
      "  '0.004*\"plume\"'),\n",
      " (6,\n",
      "  '0.026*\"mask\" + 0.010*\"infect\" + 0.009*\"use\" + 0.007*\"respir\" + '\n",
      "  '0.007*\"group\" + 0.007*\"respiratory\" + 0.006*\"protect\" + 0.005*\"medical\" + '\n",
      "  '0.005*\"control\" + 0.005*\"test\"'),\n",
      " (7,\n",
      "  '0.002*\"activ\" + 0.002*\"properti\" + 0.002*\"eo\" + 0.001*\"antimicrobial\" + '\n",
      "  '0.001*\"tgev\" + 0.001*\"acid\" + 0.001*\"mutant\" + 0.001*\"bind\" + '\n",
      "  '0.001*\"hemagglutin\" + 0.001*\"sialic\"'),\n",
      " (8,\n",
      "  '0.000*\"mask\" + 0.000*\"use\" + 0.000*\"air\" + 0.000*\"place\" + 0.000*\"acute\" + '\n",
      "  '0.000*\"patient\" + 0.000*\"travel\" + 0.000*\"respiratory\" + 0.000*\"studi\" + '\n",
      "  '0.000*\"infect\"'),\n",
      " (9,\n",
      "  '0.018*\"mask\" + 0.018*\"use\" + 0.013*\"patient\" + 0.011*\"infect\" + '\n",
      "  '0.009*\"respiratory\" + 0.006*\"measur\" + 0.006*\"transmiss\" + 0.006*\"studi\" + '\n",
      "  '0.006*\"care\" + 0.006*\"risk\"'),\n",
      " (10,\n",
      "  '0.016*\"air\" + 0.008*\"use\" + 0.007*\"cleaner\" + 0.006*\"inroom\" + 0.006*\"room\" '\n",
      "  '+ 0.005*\"technolog\" + 0.005*\"hepa\" + 0.005*\"infectious\" + 0.004*\"airborne\" '\n",
      "  '+ 0.004*\"uvgi\"'),\n",
      " (11,\n",
      "  '0.004*\"view\" + 0.003*\"obstruct\" + 0.002*\"assess\" + 0.001*\"level\" + '\n",
      "  '0.001*\"paramet\" + 0.001*\"simple\" + 0.001*\"sky\" + 0.001*\"premium\" + '\n",
      "  '0.001*\"unobstructed\" + 0.001*\"residential\"'),\n",
      " (12,\n",
      "  '0.003*\"model\" + 0.002*\"rat\" + 0.001*\"estim\" + 0.001*\"weight\" + 0.001*\"mice\" '\n",
      "  '+ 0.001*\"forecast\" + 0.001*\"encephalitis\" + 0.001*\"paramet\" + 0.001*\"error\" '\n",
      "  '+ 0.001*\"casepati\"'),\n",
      " (13,\n",
      "  '0.000*\"studi\" + 0.000*\"use\" + 0.000*\"mask\" + 0.000*\"capit\" + 0.000*\"social\" '\n",
      "  '+ 0.000*\"discoveri\" + 0.000*\"potential\" + 0.000*\"measur\" + 0.000*\"link\" + '\n",
      "  '0.000*\"reduc\"'),\n",
      " (14,\n",
      "  '0.005*\"household\" + 0.003*\"emerg\" + 0.003*\"prepared\" + 0.003*\"patient\" + '\n",
      "  '0.003*\"meningococcal\" + 0.002*\"wear\" + 0.002*\"adjust\" + 0.002*\"doctor\" + '\n",
      "  '0.002*\"consult\" + 0.002*\"primary\"'),\n",
      " (15,\n",
      "  '0.004*\"filter\" + 0.001*\"untreated\" + 0.001*\"surviv\" + 0.001*\"relative\" + '\n",
      "  '0.001*\"treat\" + 0.001*\"dialdehyd\" + 0.001*\"biocid\" + 0.001*\"inactiv\" + '\n",
      "  '0.001*\"viable\" + 0.001*\"effici\"'),\n",
      " (16,\n",
      "  '0.005*\"antibodi\" + 0.004*\"protein\" + 0.002*\"neutral\" + 0.002*\"sampl\" + '\n",
      "  '0.002*\"serum\" + 0.002*\"region\" + 0.002*\"antigen\" + 0.002*\"domain\" + '\n",
      "  '0.002*\"show\" + 0.002*\"immun\"'),\n",
      " (17,\n",
      "  '0.002*\"symptom\" + 0.002*\"physical\" + 0.002*\"flow\" + 0.002*\"stress\" + '\n",
      "  '0.002*\"psychological\" + 0.001*\"haze\" + 0.001*\"techniqu\" + 0.001*\"score\" + '\n",
      "  '0.001*\"total\" + 0.001*\"role\"'),\n",
      " (18,\n",
      "  '0.000*\"mask\" + 0.000*\"use\" + 0.000*\"infectious\" + 0.000*\"studi\" + '\n",
      "  '0.000*\"result\" + 0.000*\"measur\" + 0.000*\"method\" + 0.000*\"filter\" + '\n",
      "  '0.000*\"respiratory\" + 0.000*\"air\"'),\n",
      " (19,\n",
      "  '0.007*\"intervent\" + 0.006*\"studi\" + 0.005*\"influenza\" + 0.005*\"infect\" + '\n",
      "  '0.004*\"use\" + 0.004*\"contig\" + 0.004*\"rpe\" + 0.003*\"haplotyp\" + '\n",
      "  '0.003*\"data\" + 0.003*\"pandemic\"')]\n"
     ]
    }
   ],
   "source": [
    "#here we select the LDA model with the lowe\n",
    "scores_best = selected_best_LDA('mask', 'abstract')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe topic No. 1 is most relevant to public wearing mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 33 abstracts selected\n"
     ]
    }
   ],
   "source": [
    "# topic number 1 is most relevant to public wearing mask\n",
    "# which topic do you think is most relevant to your search\n",
    "cor_dict = select_text_from_LDA_results('mask', 'abstract', scores_best, 1)\n",
    "print (\"There are {} abstracts selected\". format(len(cor_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 articles are relevant to the topic you choose\n"
     ]
    }
   ],
   "source": [
    "# extract relevant sentences  #search keywords can be a list\n",
    "sel_sentence, sel_sentence_df = extract_relevant_sentences(cor_dict, ['mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentences</th>\n",
       "      <th>sha</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8o3l3rsf</td>\n",
       "      <td>[', escalatory quarantine, mask wearing when g...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Effectiveness of control strategies for Corona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1mu1z4xd</td>\n",
       "      <td>[' wearing a mask when going out and avoiding ...</td>\n",
       "      <td>5bb89950ec5a06e2b7f69b2a9c4213dda19b1ab0</td>\n",
       "      <td>Prediction of New Coronavirus Infection Based ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ht88wu6s</td>\n",
       "      <td>[' conclusion: to early end of the covid-19 ep...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Estimating the reproductive number and the out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nzh87aux</td>\n",
       "      <td>[' on the other hand, the model predicts that ...</td>\n",
       "      <td>9b7a0ad7b6c7f59e7a6cf1dc9d07912a273d19b5</td>\n",
       "      <td>The Waiting Time for Inter-Country Spread of P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n2r4pzan</td>\n",
       "      <td>[', wearing face mask in public venues (73', '...</td>\n",
       "      <td>b7c8e73cf095e30552a32cea04a398331c55ab41</td>\n",
       "      <td>Anticipated and current preventive behaviors i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ywb9krdp</td>\n",
       "      <td>['2%), and wear a face mask (59']</td>\n",
       "      <td>16627f4c7134394da448b1417a771d13ad7cca4a</td>\n",
       "      <td>Pandemic influenza in Australia: Using telepho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bhnh2dq4</td>\n",
       "      <td>[' if an infected person will not use a mask a...</td>\n",
       "      <td>bb9f6cef633c9baf595daae5166b11f88c1271cb</td>\n",
       "      <td>Risk of transmission of airborne infection dur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>49xvz389</td>\n",
       "      <td>['3%) were carrying out one of prevention meas...</td>\n",
       "      <td>545def8771357b4cb2875f5795a0760e97534cc9</td>\n",
       "      <td>Knowledge and attitudes of university students...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>r3in76wm</td>\n",
       "      <td>[' preventive behavior such as handwashing and...</td>\n",
       "      <td>24d7fe6bbb9945f1536fef5b281d074fe69cfc6a</td>\n",
       "      <td>Avian Influenza Risk Perception and Preventive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>e94synjc</td>\n",
       "      <td>['this research assessed factors associated wi...</td>\n",
       "      <td>14d04f36cb13550aa7769b61a079fa54031a21eb</td>\n",
       "      <td>Public health measures during an anticipated i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0                                          sentences  \\\n",
       "0   8o3l3rsf  [', escalatory quarantine, mask wearing when g...   \n",
       "1   1mu1z4xd  [' wearing a mask when going out and avoiding ...   \n",
       "2   ht88wu6s  [' conclusion: to early end of the covid-19 ep...   \n",
       "3   nzh87aux  [' on the other hand, the model predicts that ...   \n",
       "4   n2r4pzan  [', wearing face mask in public venues (73', '...   \n",
       "5   ywb9krdp                  ['2%), and wear a face mask (59']   \n",
       "6   bhnh2dq4  [' if an infected person will not use a mask a...   \n",
       "7   49xvz389  ['3%) were carrying out one of prevention meas...   \n",
       "8   r3in76wm  [' preventive behavior such as handwashing and...   \n",
       "9   e94synjc  ['this research assessed factors associated wi...   \n",
       "\n",
       "                                        sha  \\\n",
       "0                                       NaN   \n",
       "1  5bb89950ec5a06e2b7f69b2a9c4213dda19b1ab0   \n",
       "2                                       NaN   \n",
       "3  9b7a0ad7b6c7f59e7a6cf1dc9d07912a273d19b5   \n",
       "4  b7c8e73cf095e30552a32cea04a398331c55ab41   \n",
       "5  16627f4c7134394da448b1417a771d13ad7cca4a   \n",
       "6  bb9f6cef633c9baf595daae5166b11f88c1271cb   \n",
       "7  545def8771357b4cb2875f5795a0760e97534cc9   \n",
       "8  24d7fe6bbb9945f1536fef5b281d074fe69cfc6a   \n",
       "9  14d04f36cb13550aa7769b61a079fa54031a21eb   \n",
       "\n",
       "                                               title  \n",
       "0  Effectiveness of control strategies for Corona...  \n",
       "1  Prediction of New Coronavirus Infection Based ...  \n",
       "2  Estimating the reproductive number and the out...  \n",
       "3  The Waiting Time for Inter-Country Spread of P...  \n",
       "4  Anticipated and current preventive behaviors i...  \n",
       "5  Pandemic influenza in Australia: Using telepho...  \n",
       "6  Risk of transmission of airborne infection dur...  \n",
       "7  Knowledge and attitudes of university students...  \n",
       "8  Avian Influenza Risk Perception and Preventive...  \n",
       "9  Public health measures during an anticipated i...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read extracted article\n",
    "sel_sentence_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation \n",
    "We extracted 33 papers that are supposed to discuss whether using masks is useful. We annotate  whether the key sentences suggest using mask can reduce the risk of infection.\n",
    "\n",
    "Annotation \n",
    "1. ‘1’ sentences that support using a mask during a pandemic is useful \n",
    "2. ‘2’  papers that assume masks as useful and examine the public’s willingness to comply the rules,\n",
    "3. ’0’ no obvious evidence that shows using mask is protective or the protection is very little\n",
    "4. Not relevant to the above points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we need to add the stats analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "According to the key sentences in 33 abstract that discuss the topic of public using masks, only one paper suggests that there’s not enough evidence to show that mask is useful.\n",
    "There are 14 papers that suggest their results show using surgical mask during a pandemic is effective in reducing infection\n",
    "14 paper consider public individuals using masks are necessary in reducing risks of being infect, and these paper look at whether the public are willing to comply to the rules. (X papers are from  Hong Kong, based on the region of the first author)\n",
    "5 papers are not relevant to the topic\n",
    "\n",
    "Conclusion:\n",
    "government in some regions advocate using masks as a standard approach to reduce risk of infection, papers in these regions focus on whether people comply to the rules. When some government advocate that there is little evidence show that mask is effective in controlling the pandemic, nearly half of the academic papers from our search result either consider wearing masks as a standard practice that the public show comply, nearly half of the papers found evidence to support that wearing masks is effective in controlling the pandemic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: How long in incubation period? In some region (e.g. China), there’s rumour circulating that the incubation period is longer than 14 days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please help to annotate this part\n",
    "UK government advocate: 2-14 days, mean 5\n",
    "1. ‘1’  same as government advocate \n",
    "2. ‘0’  different from what the government"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/inf.ed.ac.uk/user/s16/s1690903/share/new_conda_for_me/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/afs/inf.ed.ac.uk/user/s16/s1690903/share/new_conda_for_me/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/afs/inf.ed.ac.uk/user/s16/s1690903/share/new_conda_for_me/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/afs/inf.ed.ac.uk/user/s16/s1690903/share/new_conda_for_me/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/afs/inf.ed.ac.uk/user/s16/s1690903/share/new_conda_for_me/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/afs/inf.ed.ac.uk/user/s16/s1690903/share/new_conda_for_me/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coherence score is -4.402954777107732\n",
      "coherence score is -7.622641764950241\n",
      "coherence score is -9.667138416026404\n",
      "coherence score is -8.840829560303707\n",
      "coherence score is -7.75012700862416\n",
      "coherence score is -4.690846825022652\n",
      "coherence score is -7.537936150644841\n",
      "coherence score is -8.204060613000161\n",
      "coherence score is -7.780107529965858\n",
      "coherence score is -7.243947472108755\n",
      "coherence score is -4.860236911790262\n",
      "coherence score is -6.818539222229658\n",
      "coherence score is -8.020048375633895\n",
      "coherence score is -6.931077713393968\n",
      "coherence score is -6.426623602144103\n",
      "coherence score is -4.8710456253984065\n",
      "coherence score is -6.629118614124333\n",
      "coherence score is -5.956842964386887\n",
      "coherence score is -5.355865377504925\n",
      "coherence score is -4.764257961119005\n",
      "coherence score is -4.585814626682113\n",
      "coherence score is -6.216045484929411\n",
      "coherence score is -5.112704786045706\n",
      "coherence score is -4.641328661092419\n",
      "coherence score is -3.607818546962199\n",
      "coherence score is -9.667138416026404\n",
      "[(0,\n",
      "  '0.029*\"case\" + 0.022*\"patient\" + 0.018*\"period\" + 0.016*\"incub\" + '\n",
      "  '0.016*\"day\" + 0.014*\"infect\" + 0.011*\"covid19\" + 0.009*\"estim\" + '\n",
      "  '0.009*\"transmiss\" + 0.007*\"hospit\"'),\n",
      " (1,\n",
      "  '0.002*\"educ\" + 0.002*\"crisi\" + 0.002*\"unit\" + 0.002*\"peopl\" + 0.002*\"prbc\" '\n",
      "  '+ 0.002*\"phtr\" + 0.001*\"impact\" + 0.001*\"c\" + 0.001*\"viru\" + '\n",
      "  '0.001*\"phosphatidylcholin\"'),\n",
      " (2,\n",
      "  '0.005*\"patient\" + 0.004*\"model\" + 0.004*\"case\" + 0.004*\"group\" + '\n",
      "  '0.003*\"incid\" + 0.003*\"student\" + 0.003*\"pain\" + 0.002*\"function\" + '\n",
      "  '0.002*\"time\" + 0.002*\"steroid\"'),\n",
      " (3,\n",
      "  '0.009*\"infect\" + 0.003*\"viru\" + 0.003*\"product\" + 0.003*\"p\" + '\n",
      "  '0.003*\"laboratori\" + 0.002*\"process\" + 0.002*\"incub\" + 0.002*\"sperm\" + '\n",
      "  '0.002*\"viral\" + 0.002*\"case\"'),\n",
      " (4,\n",
      "  '0.003*\"camel\" + 0.003*\"macaqu\" + 0.002*\"baboon\" + 0.002*\"cultur\" + '\n",
      "  '0.002*\"tissu\" + 0.002*\"explant\" + 0.002*\"penetr\" + 0.002*\"shfv\" + '\n",
      "  '0.002*\"merscov\" + 0.002*\"ferret\"'),\n",
      " (5,\n",
      "  '0.002*\"bacteria\" + 0.002*\"intestinal\" + 0.001*\"metabol\" + 0.001*\"metabolit\" '\n",
      "  '+ 0.001*\"saprophyt\" + 0.001*\"juic\" + 0.001*\"gastrointestinal\" + '\n",
      "  '0.001*\"trip\" + 0.001*\"parasit\" + 0.001*\"anticomplementary\"'),\n",
      " (6,\n",
      "  '0.002*\"mhv\" + 0.002*\"room\" + 0.001*\"pathway\" + 0.001*\"instrument\" + '\n",
      "  '0.001*\"dental\" + 0.001*\"ah7n9\" + 0.001*\"secretori\" + 0.001*\"constitutive\" + '\n",
      "  '0.001*\"highspe\" + 0.001*\"rotat\"'),\n",
      " (7,\n",
      "  '0.002*\"hotel\" + 0.002*\"environ\" + 0.001*\"industri\" + 0.001*\"nanocomplex\" + '\n",
      "  '0.001*\"formul\" + 0.001*\"surfac\" + 0.001*\"prepared\" + 0.001*\"vaginal\" + '\n",
      "  '0.001*\"plan\" + 0.001*\"disast\"'),\n",
      " (8,\n",
      "  '0.004*\"activ\" + 0.003*\"peptid\" + 0.002*\"chicken\" + 0.002*\"nkcell\" + '\n",
      "  '0.002*\"somni\" + 0.002*\"hcovoc43\" + 0.002*\"oxid\" + 0.002*\"accumul\" + '\n",
      "  '0.002*\"bovine\" + 0.001*\"astrocyt\"'),\n",
      " (9,\n",
      "  '0.003*\"delay\" + 0.002*\"system\" + 0.001*\"nonautonomous\" + 0.001*\"pattern\" + '\n",
      "  '0.001*\"spatial\" + 0.001*\"lyapunov\" + 0.001*\"chaotic\" + 0.001*\"perman\" + '\n",
      "  '0.001*\"numerical\" + 0.001*\"ture\"'),\n",
      " (10,\n",
      "  '0.027*\"cell\" + 0.019*\"protein\" + 0.009*\"express\" + 0.009*\"viru\" + '\n",
      "  '0.008*\"incub\" + 0.007*\"infect\" + 0.006*\"viral\" + 0.006*\"receptor\" + '\n",
      "  '0.005*\"bind\" + 0.005*\"activ\"'),\n",
      " (11,\n",
      "  '0.009*\"diseas\" + 0.008*\"viru\" + 0.007*\"infect\" + 0.007*\"transmiss\" + '\n",
      "  '0.007*\"incub\" + 0.006*\"outbreak\" + 0.006*\"studi\" + 0.006*\"use\" + '\n",
      "  '0.005*\"case\" + 0.005*\"caus\"'),\n",
      " (12,\n",
      "  '0.002*\"t\" + 0.002*\"apical\" + 0.002*\"protein\" + 0.002*\"polypeptid\" + '\n",
      "  '0.002*\"basolateral\" + 0.002*\"cell\" + 0.002*\"mice\" + 0.002*\"supernat\" + '\n",
      "  '0.002*\"memori\" + 0.001*\"purif\"'),\n",
      " (13,\n",
      "  '0.001*\"airborne\" + 0.001*\"indoor\" + 0.000*\"occup\" + '\n",
      "  '0.000*\"shortincubationperiod\" + 0.000*\"environ\" + 0.000*\"theoretical\" + '\n",
      "  '0.000*\"room\" + 0.000*\"ventil\" + 0.000*\"feather\" + 0.000*\"zoonos\"'),\n",
      " (14,\n",
      "  '0.003*\"parasit\" + 0.002*\"prolifer\" + 0.002*\"idv\" + 0.002*\"lymphocyt\" + '\n",
      "  '0.002*\"rat\" + 0.001*\"transcript\" + 0.001*\"nigra\" + 0.001*\"erythrocyt\" + '\n",
      "  '0.001*\"brain\" + 0.001*\"popul\"'),\n",
      " (15,\n",
      "  '0.014*\"cell\" + 0.011*\"viru\" + 0.006*\"activ\" + 0.004*\"ace2\" + 0.004*\"incub\" '\n",
      "  '+ 0.004*\"shed\" + 0.004*\"express\" + 0.004*\"inhibitor\" + 0.004*\"infect\" + '\n",
      "  '0.003*\"cftr\"'),\n",
      " (16,\n",
      "  '0.005*\"cell\" + 0.003*\"strain\" + 0.003*\"insulin\" + 0.002*\"hpev1\" + '\n",
      "  '0.002*\"endothelial\" + 0.002*\"peptid\" + 0.002*\"recombinant\" + 0.002*\"virus\" '\n",
      "  '+ 0.002*\"fibril\" + 0.002*\"result\"'),\n",
      " (17,\n",
      "  '0.014*\"infect\" + 0.013*\"cell\" + 0.013*\"viru\" + 0.013*\"incub\" + 0.009*\"use\" '\n",
      "  '+ 0.009*\"detect\" + 0.007*\"result\" + 0.007*\"viral\" + 0.006*\"studi\" + '\n",
      "  '0.006*\"diseas\"'),\n",
      " (18,\n",
      "  '0.002*\"cadmium\" + 0.002*\"calv\" + 0.002*\"salmonella\" + 0.002*\"student\" + '\n",
      "  '0.002*\"cdcl2\" + 0.001*\"rotaviru\" + 0.001*\"veterinary\" + 0.001*\"preventive\" '\n",
      "  '+ 0.001*\"toxic\" + 0.001*\"excret\"'),\n",
      " (19,\n",
      "  '0.001*\"safeti\" + 0.001*\"airway\" + 0.001*\"rtd1\" + 0.001*\"toler\" + '\n",
      "  '0.001*\"inflamm\" + 0.001*\"bronchial\" + 0.001*\"peptid\" + 0.001*\"stabil\" + '\n",
      "  '0.001*\"therapeutic\" + 0.000*\"α26\"')]\n"
     ]
    }
   ],
   "source": [
    "scores_best = selected_best_LDA('incubation', 'abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 205 abstracts selected\n"
     ]
    }
   ],
   "source": [
    "# topic number 0 is most relevant to public wearing mask\n",
    "# which topic do you think is most relevant to your search\n",
    "cor_dict = select_text_from_LDA_results('incubation', 'abstract', scores_best, 0)\n",
    "print (\"There are {} abstracts selected\". format(len(cor_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205 articles are relevant to the topic you choose\n"
     ]
    }
   ],
   "source": [
    "# extract relevant sentences  #search keywords can be a list\n",
    "sel_sentence, sel_sentence_df = extract_relevant_sentences(cor_dict, ['incubation', 'day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentences</th>\n",
       "      <th>sha</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>h89scli5</td>\n",
       "      <td>[' for monitored individuals, we identified un...</td>\n",
       "      <td>b5161b031c7f720562e94735a018d1c3c8be3ae5</td>\n",
       "      <td>Quantifying the Risk and Cost of Active Monito...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ykofrn9i</td>\n",
       "      <td>[' using publicly available event-date data fr...</td>\n",
       "      <td>cbc05d14c57b91081970a232ab83bc993f998fe2</td>\n",
       "      <td>Incubation Period and Other Epidemiological Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u8goc7io</td>\n",
       "      <td>[' using the travel history and symptom onset ...</td>\n",
       "      <td>12fac9aedb1a09a3922a3c084ce4723708e463d6</td>\n",
       "      <td>The incubation period of 2019-nCoV infections ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2wshgzjk</td>\n",
       "      <td>['7) of infected travellers would not be detec...</td>\n",
       "      <td>a01672035e0b9d21f9a934b9c9071610513325f2</td>\n",
       "      <td>Effectiveness of airport screening at detectin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vspnuxz9</td>\n",
       "      <td>['0 days (95% credible interval [cri]: 3', '6 ...</td>\n",
       "      <td>a1bff76ce360e8990b0a4ee2a5228a6e6e63d9c1</td>\n",
       "      <td>Serial interval of novel coronavirus (2019-nCo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cetdqgff</td>\n",
       "      <td>['8% as of 20 february, the 75752 confirmed ca...</td>\n",
       "      <td>bb8e3d331bb2975e1c644c8729b842797da2d626</td>\n",
       "      <td>Machine learning using intrinsic genomic signa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ra3t6kmm</td>\n",
       "      <td>[' compared to previous analyses, an important...</td>\n",
       "      <td>c85f571a674c7fed0ccb9176e9cf9f3d3659ca32</td>\n",
       "      <td>Analysis of the epidemic growth of the early 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tovfd9lw</td>\n",
       "      <td>[' the median incubation period was 3', '0 day...</td>\n",
       "      <td>dfb0fedbeed56bd2b795a67faab28295afc14c96</td>\n",
       "      <td>Clinical characteristics of 2019 novel coronav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>45g12waw</td>\n",
       "      <td>[' we collected extensive individual case repo...</td>\n",
       "      <td>36a5f6d55d7c5f67d4344e36da0a72856ad3dda0</td>\n",
       "      <td>The Novel Coronavirus, 2019-nCoV, is Highly Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>er3zmcz2</td>\n",
       "      <td>[' there have been reports external icon of sp...</td>\n",
       "      <td>815745bf1b522d33fd7371cc9a6561a2a93ef87e</td>\n",
       "      <td>Simulating the infected population and spread ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0                                          sentences  \\\n",
       "0   h89scli5  [' for monitored individuals, we identified un...   \n",
       "1   ykofrn9i  [' using publicly available event-date data fr...   \n",
       "2   u8goc7io  [' using the travel history and symptom onset ...   \n",
       "3   2wshgzjk  ['7) of infected travellers would not be detec...   \n",
       "4   vspnuxz9  ['0 days (95% credible interval [cri]: 3', '6 ...   \n",
       "5   cetdqgff  ['8% as of 20 february, the 75752 confirmed ca...   \n",
       "6   ra3t6kmm  [' compared to previous analyses, an important...   \n",
       "7   tovfd9lw  [' the median incubation period was 3', '0 day...   \n",
       "8   45g12waw  [' we collected extensive individual case repo...   \n",
       "9   er3zmcz2  [' there have been reports external icon of sp...   \n",
       "\n",
       "                                        sha  \\\n",
       "0  b5161b031c7f720562e94735a018d1c3c8be3ae5   \n",
       "1  cbc05d14c57b91081970a232ab83bc993f998fe2   \n",
       "2  12fac9aedb1a09a3922a3c084ce4723708e463d6   \n",
       "3  a01672035e0b9d21f9a934b9c9071610513325f2   \n",
       "4  a1bff76ce360e8990b0a4ee2a5228a6e6e63d9c1   \n",
       "5  bb8e3d331bb2975e1c644c8729b842797da2d626   \n",
       "6  c85f571a674c7fed0ccb9176e9cf9f3d3659ca32   \n",
       "7  dfb0fedbeed56bd2b795a67faab28295afc14c96   \n",
       "8  36a5f6d55d7c5f67d4344e36da0a72856ad3dda0   \n",
       "9  815745bf1b522d33fd7371cc9a6561a2a93ef87e   \n",
       "\n",
       "                                               title  \n",
       "0  Quantifying the Risk and Cost of Active Monito...  \n",
       "1  Incubation Period and Other Epidemiological Ch...  \n",
       "2  The incubation period of 2019-nCoV infections ...  \n",
       "3  Effectiveness of airport screening at detectin...  \n",
       "4  Serial interval of novel coronavirus (2019-nCo...  \n",
       "5  Machine learning using intrinsic genomic signa...  \n",
       "6  Analysis of the epidemic growth of the early 2...  \n",
       "7  Clinical characteristics of 2019 novel coronav...  \n",
       "8  The Novel Coronavirus, 2019-nCoV, is Highly Co...  \n",
       "9  Simulating the infected population and spread ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read extracted article\n",
    "sel_sentence_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Are asymptomatic patients infectious?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coherence score is -2.333875362764049\n",
      "coherence score is -4.70447389062267\n",
      "coherence score is -6.939599491635526\n",
      "coherence score is -8.440505363564451\n",
      "coherence score is -9.591134816334584\n",
      "coherence score is -2.2594033960424147\n",
      "coherence score is -5.105876829676597\n",
      "coherence score is -6.9371475741261035\n",
      "coherence score is -8.606789439278637\n",
      "coherence score is -9.453634935286304\n",
      "coherence score is -2.638911020212841\n",
      "coherence score is -4.846954903243043\n",
      "coherence score is -6.8515540183404955\n",
      "coherence score is -8.924401332546264\n",
      "coherence score is -8.268359620682485\n",
      "coherence score is -2.4049378700075303\n",
      "coherence score is -4.651142459964543\n",
      "coherence score is -6.56690398681833\n",
      "coherence score is -7.81408598379605\n",
      "coherence score is -5.9898250531948944\n",
      "coherence score is -2.334124552642998\n",
      "coherence score is -4.078897796588015\n",
      "coherence score is -6.8391754668949485\n",
      "coherence score is -6.1568698549644205\n",
      "coherence score is -4.795885092862488\n",
      "coherence score is -9.591134816334584\n",
      "[(0,\n",
      "  '0.002*\"calv\" + 0.001*\"ioae\" + 0.001*\"stent\" + 0.001*\"graft\" + '\n",
      "  '0.001*\"fenestrated\" + 0.001*\"function\" + 0.001*\"branch\" + 0.001*\"bovin\" + '\n",
      "  '0.001*\"moderate\" + 0.001*\"lung\"'),\n",
      " (1,\n",
      "  '0.000*\"cell\" + 0.000*\"infect\" + 0.000*\"clinical\" + 0.000*\"viru\" + '\n",
      "  '0.000*\"diseas\" + 0.000*\"asymptomatic\" + 0.000*\"macaqu\" + 0.000*\"case\" + '\n",
      "  '0.000*\"allergic\" + 0.000*\"strain\"'),\n",
      " (2,\n",
      "  '0.001*\"yield\" + 0.001*\"biomark\" + 0.001*\"apoa1\" + 0.000*\"alveolar\" + '\n",
      "  '0.000*\"fob\" + 0.000*\"reticular\" + 0.000*\"diagnostic\" + 0.000*\"nodular\" + '\n",
      "  '0.000*\"fulllength\" + 0.000*\"infiltr\"'),\n",
      " (3,\n",
      "  '0.009*\"children\" + 0.008*\"patient\" + 0.008*\"allergic\" + 0.006*\"effect\" + '\n",
      "  '0.005*\"young\" + 0.005*\"case\" + 0.005*\"model\" + 0.004*\"asthma\" + '\n",
      "  '0.004*\"clinical\" + 0.004*\"treatment\"'),\n",
      " (4,\n",
      "  '0.009*\"cell\" + 0.008*\"bat\" + 0.006*\"respons\" + 0.005*\"infect\" + '\n",
      "  '0.004*\"immune\" + 0.004*\"dog\" + 0.004*\"viral\" + 0.003*\"gene\" + '\n",
      "  '0.003*\"protein\" + 0.002*\"macaqu\"'),\n",
      " (5,\n",
      "  '0.002*\"inflamm\" + 0.002*\"intraamniotic\" + 0.001*\"r\" + 0.001*\"piglet\" + '\n",
      "  '0.001*\"estim\" + 0.001*\"day\" + 0.001*\"method\" + 0.001*\"astrovirus\" + '\n",
      "  '0.001*\"oper\" + 0.001*\"cadmium\"'),\n",
      " (6,\n",
      "  '0.001*\"plant\" + 0.001*\"lifestyl\" + 0.000*\"influenza\" + 0.000*\"persistent\" + '\n",
      "  '0.000*\"virus\" + 0.000*\"eukaryotic\" + 0.000*\"partitivirida\" + '\n",
      "  '0.000*\"endornaviru\" + 0.000*\"vast\" + 0.000*\"wellcharacterized\"'),\n",
      " (7,\n",
      "  '0.001*\"ccv\" + 0.001*\"renal\" + 0.001*\"hypouricaemia\" + 0.001*\"urate\" + '\n",
      "  '0.000*\"uric\" + 0.000*\"stone\" + 0.000*\"inherit\" + 0.000*\"urat1\" + '\n",
      "  '0.000*\"cat\" + 0.000*\"handl\"'),\n",
      " (8,\n",
      "  '0.003*\"case\" + 0.001*\"avid\" + 0.001*\"sleep\" + 0.001*\"chest\" + 0.001*\"ct\" + '\n",
      "  '0.001*\"infect\" + 0.001*\"enfant\" + 0.001*\"patient\" + 0.001*\"imag\" + '\n",
      "  '0.001*\"acid\"'),\n",
      " (9,\n",
      "  '0.002*\"cage\" + 0.002*\"dog\" + 0.002*\"ecov\" + 0.002*\"hors\" + 0.001*\"piglet\" + '\n",
      "  '0.001*\"pheasant\" + 0.001*\"pid\" + 0.001*\"swab\" + 0.001*\"infect\" + '\n",
      "  '0.001*\"autoantibodi\"'),\n",
      " (10,\n",
      "  '0.002*\"blockag\" + 0.002*\"traffic\" + 0.001*\"market\" + 0.001*\"wet\" + '\n",
      "  '0.001*\"puuv\" + 0.001*\"quarantin\" + 0.001*\"id99\" + 0.001*\"htnv\" + '\n",
      "  '0.001*\"shrew\" + 0.001*\"hamster\"'),\n",
      " (11,\n",
      "  '0.001*\"mscpv1\" + 0.001*\"env\" + 0.001*\"bat\" + 0.001*\"wild\" + 0.001*\"pfv\" + '\n",
      "  '0.001*\"carnivor\" + 0.001*\"cakov\" + 0.001*\"kobuvirus\" + 0.001*\"gp48tm\" + '\n",
      "  '0.001*\"helic\"'),\n",
      " (12,\n",
      "  '0.001*\"puppi\" + 0.001*\"clean\" + 0.001*\"hcw\" + 0.001*\"rct\" + 0.001*\"pkdl\" + '\n",
      "  '0.001*\"room\" + 0.001*\"cpv\" + 0.001*\"ccov\" + 0.001*\"diarrhoea\" + '\n",
      "  '0.001*\"infector\"'),\n",
      " (13,\n",
      "  '0.001*\"proteas\" + 0.001*\"inhibitor\" + 0.001*\"gut\" + 0.001*\"3cl\" + '\n",
      "  '0.001*\"microbiom\" + 0.001*\"felin\" + 0.001*\"astvinfect\" + 0.000*\"enteric\" + '\n",
      "  '0.000*\"taxa\" + 0.000*\"astv\"'),\n",
      " (14,\n",
      "  '0.001*\"afadr\" + 0.001*\"fshd\" + 0.001*\"cbc\" + 0.001*\"express\" + '\n",
      "  '0.001*\"intestinal\" + 0.001*\"abund\" + 0.001*\"dux4fl\" + 0.001*\"skeletal\" + '\n",
      "  '0.001*\"fshdlike\" + 0.001*\"cytokin\"'),\n",
      " (15,\n",
      "  '0.001*\"student\" + 0.001*\"offspr\" + 0.001*\"tonsil\" + 0.001*\"cmml\" + '\n",
      "  '0.001*\"israeli\" + 0.001*\"obstruct\" + 0.001*\"btv3\" + 0.001*\"reassort\" + '\n",
      "  '0.001*\"bovi\" + 0.001*\"adenoid\"'),\n",
      " (16,\n",
      "  '0.002*\"bat\" + 0.002*\"model\" + 0.002*\"infect\" + 0.002*\"screen\" + '\n",
      "  '0.002*\"dromedari\" + 0.002*\"estim\" + 0.001*\"virus\" + 0.001*\"camel\" + '\n",
      "  '0.001*\"mhc\" + 0.001*\"peptid\"'),\n",
      " (17,\n",
      "  '0.017*\"infect\" + 0.015*\"respiratory\" + 0.014*\"detect\" + 0.013*\"patient\" + '\n",
      "  '0.013*\"asymptomatic\" + 0.012*\"children\" + 0.010*\"viru\" + 0.009*\"studi\" + '\n",
      "  '0.009*\"sampl\" + 0.009*\"virus\"'),\n",
      " (18,\n",
      "  '0.001*\"ipd\" + 0.001*\"mhva59\" + 0.001*\"microbiota\" + 0.001*\"chadox1\" + '\n",
      "  '0.001*\"homozygous\" + 0.000*\"children\" + 0.000*\"f11\" + 0.000*\"immunogen\" + '\n",
      "  '0.000*\"candid\" + 0.000*\"pfu\"'),\n",
      " (19,\n",
      "  '0.025*\"infect\" + 0.014*\"case\" + 0.011*\"asymptomatic\" + 0.011*\"diseas\" + '\n",
      "  '0.010*\"patient\" + 0.010*\"viru\" + 0.008*\"transmiss\" + 0.005*\"viral\" + '\n",
      "  '0.005*\"severe\" + 0.005*\"clinical\"')]\n"
     ]
    }
   ],
   "source": [
    "scores_best = selected_best_LDA('asymptomatic', 'abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 355 abstracts selected\n"
     ]
    }
   ],
   "source": [
    "# topic number 19 is most relevant to public wearing mask\n",
    "# which topic do you think is most relevant to your search\n",
    "cor_dict = select_text_from_LDA_results('asymptomatic', 'abstract', scores_best, 19)\n",
    "print (\"There are {} abstracts selected\". format(len(cor_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136 articles are relevant to the topic you choose\n"
     ]
    }
   ],
   "source": [
    "# extract relevant sentences  #search keywords can be a list\n",
    "sel_sentence, sel_sentence_df = extract_relevant_sentences(cor_dict, ['transmission'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentences</th>\n",
       "      <th>sha</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>j3avpu1y</td>\n",
       "      <td>[' no data on person-to-person or nosocomial t...</td>\n",
       "      <td>52f88e8d4b44c47b9afd25b59eb9b7f85ab95275</td>\n",
       "      <td>A familial cluster of pneumonia associated wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>ue6e3ua3</td>\n",
       "      <td>[' dromedary camels, hosts for mers-cov, are i...</td>\n",
       "      <td>72076bc07694d7ba7e9fd2adfcb10b11fde1c9ba; 76b7...</td>\n",
       "      <td>Middle East respiratory syndrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1nhlu89c</td>\n",
       "      <td>[' however, the recent report on asymptomatic ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus disease-2019: is fever an adequate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>kwq2y3il</td>\n",
       "      <td>[' therefore, there is still a theoretical ris...</td>\n",
       "      <td>a9a4101b25236a4fc0e14a9cbdd904ca8b2baffd</td>\n",
       "      <td>Coronavirus Disease 2019: Coronaviruses and Bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>6kuh4njb</td>\n",
       "      <td>[' conclusion being able to protect healthcare...</td>\n",
       "      <td>5ec1bf2fc5d286672feb316e70accdd302d7ed50</td>\n",
       "      <td>MERS-CoV infection among healthcare workers an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>k3f7ohzg</td>\n",
       "      <td>[' the measures to prevent transmission was ve...</td>\n",
       "      <td>14dbf1c01f2c422c1aefee32f094cc524ea03af1</td>\n",
       "      <td>Characteristics of COVID-19 infection in Beijing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>kiq6xb6k</td>\n",
       "      <td>[' interpretation person-to-person transmissio...</td>\n",
       "      <td>ad0e9c151402df00786e0aa6dd30987004966deb</td>\n",
       "      <td>First known person-to-person transmission of s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>626ch774</td>\n",
       "      <td>['we simulated 100 2019-ncov infected travelle...</td>\n",
       "      <td>09e25e413faba97b87efc701d1ab8d2a18386efb; 4e55...</td>\n",
       "      <td>Effectiveness of airport screening at detectin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>pth2d40p</td>\n",
       "      <td>[' in addition, nosocomial infection of hospit...</td>\n",
       "      <td>89a8918f7e3044b89642aaa74defc7381abef482; 1f5c...</td>\n",
       "      <td>Asymptomatic carrier state, acute respiratory ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>hfkzu18p</td>\n",
       "      <td>[' here we highlight nine most important resea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SARS-CoV-2 and COVID-19: The most important re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                          sentences  \\\n",
       "126   j3avpu1y  [' no data on person-to-person or nosocomial t...   \n",
       "127   ue6e3ua3  [' dromedary camels, hosts for mers-cov, are i...   \n",
       "128   1nhlu89c  [' however, the recent report on asymptomatic ...   \n",
       "129   kwq2y3il  [' therefore, there is still a theoretical ris...   \n",
       "130   6kuh4njb  [' conclusion being able to protect healthcare...   \n",
       "131   k3f7ohzg  [' the measures to prevent transmission was ve...   \n",
       "132   kiq6xb6k  [' interpretation person-to-person transmissio...   \n",
       "133   626ch774  ['we simulated 100 2019-ncov infected travelle...   \n",
       "134   pth2d40p  [' in addition, nosocomial infection of hospit...   \n",
       "135   hfkzu18p  [' here we highlight nine most important resea...   \n",
       "\n",
       "                                                   sha  \\\n",
       "126           52f88e8d4b44c47b9afd25b59eb9b7f85ab95275   \n",
       "127  72076bc07694d7ba7e9fd2adfcb10b11fde1c9ba; 76b7...   \n",
       "128                                                NaN   \n",
       "129           a9a4101b25236a4fc0e14a9cbdd904ca8b2baffd   \n",
       "130           5ec1bf2fc5d286672feb316e70accdd302d7ed50   \n",
       "131           14dbf1c01f2c422c1aefee32f094cc524ea03af1   \n",
       "132           ad0e9c151402df00786e0aa6dd30987004966deb   \n",
       "133  09e25e413faba97b87efc701d1ab8d2a18386efb; 4e55...   \n",
       "134  89a8918f7e3044b89642aaa74defc7381abef482; 1f5c...   \n",
       "135                                                NaN   \n",
       "\n",
       "                                                 title  \n",
       "126  A familial cluster of pneumonia associated wit...  \n",
       "127                   Middle East respiratory syndrome  \n",
       "128  Coronavirus disease-2019: is fever an adequate...  \n",
       "129  Coronavirus Disease 2019: Coronaviruses and Bl...  \n",
       "130  MERS-CoV infection among healthcare workers an...  \n",
       "131   Characteristics of COVID-19 infection in Beijing  \n",
       "132  First known person-to-person transmission of s...  \n",
       "133  Effectiveness of airport screening at detectin...  \n",
       "134  Asymptomatic carrier state, acute respiratory ...  \n",
       "135  SARS-CoV-2 and COVID-19: The most important re...  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_sentence_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: Will the virus disappear in the summer? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coherence score is -3.0018444354246148\n",
      "coherence score is -3.7713565323755445\n",
      "coherence score is -4.853842927051636\n",
      "coherence score is -5.115316283418001\n",
      "coherence score is -5.275887027502832\n",
      "coherence score is -2.7310261720813687\n",
      "coherence score is -3.365557896859708\n",
      "coherence score is -3.823341883449962\n",
      "coherence score is -4.286592442380965\n",
      "coherence score is -4.657320289835465\n",
      "coherence score is -2.686902420165036\n",
      "coherence score is -3.455505499881666\n",
      "coherence score is -3.4104528813580304\n",
      "coherence score is -3.9792818874763447\n",
      "coherence score is -4.118397656468215\n",
      "coherence score is -2.7034845774008556\n",
      "coherence score is -3.4266148606542437\n",
      "coherence score is -3.2756509301082404\n",
      "coherence score is -3.5675747343801505\n",
      "coherence score is -3.359507266843969\n",
      "coherence score is -2.7106744166911487\n",
      "coherence score is -2.9796069633608218\n",
      "coherence score is -2.9585235165206862\n",
      "coherence score is -3.077832723977046\n",
      "coherence score is -2.9506491538081954\n",
      "coherence score is -5.275887027502832\n",
      "[(0,\n",
      "  '0.024*\"respiratory\" + 0.018*\"infect\" + 0.016*\"season\" + 0.016*\"virus\" + '\n",
      "  '0.015*\"viru\" + 0.013*\"influenza\" + 0.012*\"detect\" + 0.012*\"year\" + '\n",
      "  '0.012*\"studi\" + 0.011*\"children\"'),\n",
      " (1,\n",
      "  '0.002*\"recur\" + 0.001*\"establish\" + 0.001*\"anim\" + 0.001*\"recurr\" + '\n",
      "  '0.001*\"diseas\" + 0.001*\"unpredictable\" + 0.001*\"fragmentary\" + '\n",
      "  '0.001*\"reservoir\" + 0.001*\"physiolog\" + 0.001*\"emergent\"'),\n",
      " (2,\n",
      "  '0.000*\"pathogen\" + 0.000*\"case\" + 0.000*\"dengu\" + 0.000*\"fever\" + '\n",
      "  '0.000*\"screen\" + 0.000*\"infect\" + 0.000*\"model\" + 0.000*\"interact\" + '\n",
      "  '0.000*\"data\" + 0.000*\"use\"'),\n",
      " (3,\n",
      "  '0.007*\"effect\" + 0.007*\"strain\" + 0.005*\"litter