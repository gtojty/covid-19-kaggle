{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Design\n",
    "\n",
    "Knowledge gap between public and specialists and uncertainties are an important factors that drive pandemic anxiety, in this task, we will examine papers that discuss some of the controversial topics that contribute to rumours and anxiety\n",
    "\n",
    "Here I develop a search system to extract sentences from abstracts that are relevant to a question. The questions are associated with rumour and uncertain information circulating in the public. We can try different questions in here, and an important part is to evaluate the search system with human annotation baseline if we want to push forward this work as a paper. \n",
    "\n",
    "### Step 1:\n",
    "The search system first extract abstract contains a keyword (e.g. ‘mask’), then we use LDA to group the abstract topics. We identify a topic that is  most relevant to the question and we extract abstracts that contain the target topic. The system sentences that contain the keyword from the relevant abstracts. The standard apporach of a search system is to used TFIDF to rank documents, here we use LDA topic modeling on nouns, verbs and adjectives of the abstract. Users can decide the relevant information when they know what are the most frequent keywords in each topic.\n",
    "\n",
    "The benefit of this approach is that when we want to know the relevant content for a question, we don't know what are the keywords in the article are more relevant to the question we ask, because the users are usually not farmiliar with academic papers. In our system, the topic keywords serve as prime for the query in the next step for extracting sentences in the abstract.\n",
    "\n",
    "### Step 2:\n",
    "We manually annotate the key sentences to identify information in these key sentences. \n",
    "\n",
    "\n",
    "Keywords:\n",
    "Incubation period, asymptomatic, mask, death rate, paracetamone\n",
    "\n",
    "\n",
    "### Annotation\n",
    "To understand the answer to the relevant question, we need to annotate the stance of the results, such as, does the abstract for / against the statement. \n",
    "\n",
    "To evaluate the search system, we need to annotate the relevance of the retrieved result. Please refer to each section for annotation guildline\n",
    "\n",
    "Retrieved results and annotations are in this document \n",
    "https://docs.google.com/spreadsheets/d/1-eWEqji7mLXNF0Z9KH8RE5djcxK-97dUHzPWY7GEhI8/edit?usp=sharing\n",
    "\n",
    "The document contains:\n",
    "\n",
    "1. annotation of stance:\n",
    "sheet: mask, incubation, asymtomatic, seasonality, column 'stance'\n",
    "\n",
    "2. annotation for relevant\n",
    "sheet: mask, incubation, asymtomatic, seasonality, column 'relevance'\n",
    "\n",
    "3. annotation for system evaluation \n",
    "sheet: system_eval_varname, column 'relevance'\n",
    "\n",
    "\n",
    "### Evaluation of the system:\n",
    "For evaluation of the system, we first use keyword approach to extract abstract contains the keywords. Then we mannually annotate whether the abstract extracted are relevant to the question asked. We compute the precision and recall of our system based on this annotation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search System "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from collections import defaultdict\n",
    "import string\n",
    "from gensim.models import CoherenceModel\n",
    "import gensim\n",
    "from pprint import pprint\n",
    "import spacy,en_core_web_sm\n",
    "from nltk.stem import PorterStemmer\n",
    "import os\n",
    "import json\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "import re\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read metadata into dictionary format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaData:\n",
    "    def __init__(self):\n",
    "        \"\"\"Define varibles.\"\"\"\n",
    "        # path and data\n",
    "        self.path = '/afs/inf.ed.ac.uk/user/s16/s1690903/share/cov19_2/'\n",
    "        self.meta_data = pd.read_csv(self.path + 'metadata.csv')\n",
    "\n",
    "    def data_dict(self):\n",
    "        \"\"\"Convert df to dictionary. \"\"\"\n",
    "        mydict = lambda: defaultdict(mydict)\n",
    "        meta_data_dict = mydict()\n",
    "\n",
    "        for cord_uid, abstract, title, sha in zip(self.meta_data['cord_uid'], self.meta_data['abstract'], self.meta_data['title'], self.meta_data['sha']):\n",
    "            meta_data_dict[cord_uid]['title'] = title\n",
    "            meta_data_dict[cord_uid]['abstract'] = abstract\n",
    "            meta_data_dict[cord_uid]['sha'] = sha\n",
    "\n",
    "        return meta_data_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract documents contain keywords, preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractText:\n",
    "    \"\"\"Extract text according to keywords or phrases\"\"\"\n",
    "\n",
    "    def __init__(self, metaDict, keyword, variable):\n",
    "        \"\"\"Define varibles.\"\"\"\n",
    "        self.path = '/afs/inf.ed.ac.uk/user/s16/s1690903/share/cov19_2/'\n",
    "        self.metadata = metaDict\n",
    "        self.keyword = keyword\n",
    "        self.variable = variable\n",
    "\n",
    "\n",
    "    def simple_preprocess(self):\n",
    "        \"\"\"Simple text process: lower case, remove punc. \"\"\"\n",
    "        mydict = lambda: defaultdict(mydict)\n",
    "        cleaned = mydict()\n",
    "        for k, v in self.metadata.items():\n",
    "            sent = v[self.variable]\n",
    "            sent = str(sent).lower().translate(str.maketrans('', '', string.punctuation))\n",
    "            cleaned[k]['processed_text'] = sent\n",
    "            cleaned[k]['sha'] = v['sha']\n",
    "            cleaned[k]['title'] = v['title']\n",
    "\n",
    "        return cleaned\n",
    "\n",
    "    def very_simple_preprocess(self):\n",
    "        \"\"\"Simple text process: lower case only. \"\"\"\n",
    "        mydict = lambda: defaultdict(mydict)\n",
    "        cleaned = mydict()\n",
    "        for k, v in self.metadata.items():\n",
    "            sent = v[self.variable]\n",
    "            sent = str(sent)\n",
    "            #sent = str(sent).lower()\n",
    "            cleaned[k]['processed_text'] = sent\n",
    "            cleaned[k]['sha'] = v['sha']\n",
    "            cleaned[k]['title'] = v['title']\n",
    "\n",
    "        return cleaned\n",
    "     \n",
    "\n",
    "    def extract_w_keywords(self):\n",
    "        \"\"\"Select content with keywords.\"\"\"\n",
    "        ps = PorterStemmer()\n",
    "        mydict = lambda: defaultdict(mydict)\n",
    "        selected = mydict()\n",
    "        textdict = self.simple_preprocess()\n",
    "        \n",
    "        for k, v in textdict.items():\n",
    "            if self.keyword in v['processed_text'].split():\n",
    "                #print(ps.stem(str(self.keyword)))\n",
    "                selected[k]['processed_text'] = v['processed_text']\n",
    "                selected[k]['sha'] = v['sha']\n",
    "                selected[k]['title'] = v['title']\n",
    "        return selected\n",
    "\n",
    "    def extract_w_keywords_punc(self):\n",
    "        \"\"\"Select content with keywords, with punctuations in text\"\"\"\n",
    "        ps = PorterStemmer()\n",
    "        mydict = lambda: defaultdict(mydict)\n",
    "        selected = mydict()\n",
    "        textdict = self.very_simple_preprocess()\n",
    "        \n",
    "        for k, v in textdict.items():\n",
    "            if ps.stem(str(self.keyword)) in ps.stem(str(v['processed_text'].split())):\n",
    "                selected[k]['processed_text'] = v['processed_text']\n",
    "                selected[k]['sha'] = v['sha']\n",
    "                selected[k]['title'] = v['title']\n",
    "        return selected\n",
    "\n",
    "    def get_noun_verb(self, text):\n",
    "        \"\"\"get noun trunks for the lda model,\n",
    "        change noun and verb part to decide what\n",
    "        you want to use as input for LDA\"\"\"\n",
    "        ps = PorterStemmer()\n",
    "      \n",
    "        #find nound trunks\n",
    "        nlp = en_core_web_sm.load()\n",
    "        all_extracted = {}\n",
    "        for k, v in text.items():\n",
    "            #v = v.replace('incubation period', 'incubation_period')\n",
    "            doc = nlp(v)\n",
    "            nouns = ' '.join(str(v) for v in doc if v.pos_ is 'NOUN').split()\n",
    "            verbs = ' '.join(ps.stem(str(v)) for v in doc if v.pos_ is 'VERB').split()\n",
    "            adj = ' '.join(str(v) for v in doc if v.pos_ is 'ADJ').split()\n",
    "            all_w = nouns + verbs + adj\n",
    "            all_extracted[k] = all_w\n",
    "      \n",
    "        return all_extracted\n",
    "\n",
    "    def get_noun_verb2(self, text):\n",
    "        \"\"\"get noun trunks for the lda model,\n",
    "        change noun and verb part to decide what\n",
    "        you want to use as input for LDA\"\"\"\n",
    "        ps = PorterStemmer()\n",
    "      \n",
    "        #find nound trunks\n",
    "        nlp = en_core_web_sm.load()\n",
    "        all_extracted = {}\n",
    "        for k, v in text.items():\n",
    "            #v = v.replace('incubation period', 'incubation_period')\n",
    "            doc = nlp(v['processed_text'])\n",
    "            nouns = ' '.join(ps.stem(str(v)) for v in doc if v.pos_ is 'NOUN').split()\n",
    "            verbs = ' '.join(ps.stem(str(v)) for v in doc if v.pos_ is 'VERB').split()\n",
    "            adj = ' '.join(str(v) for v in doc if v.pos_ is 'ADJ').split()\n",
    "            all_w = nouns + verbs + adj\n",
    "            all_extracted[k] = all_w\n",
    "      \n",
    "        return all_extracted\n",
    "\n",
    "    def tokenization(self, text):\n",
    "        \"\"\"get noun trunks for the lda model,\n",
    "        change noun and verb part to decide what\n",
    "        you want to use as input for the next step\"\"\"\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "        all_extracted = {}\n",
    "        for k, v in text.items():\n",
    "            doc = nlp(v)\n",
    "            all_extracted[k] = [w.text for w in doc]\n",
    "      \n",
    "        return all_extracted\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using LDA to rank documents\n",
    "LDA is optimized by coherence score u_mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDATopic:\n",
    "    def __init__(self, processed_text, topic_num, alpha, eta):\n",
    "        \"\"\"Define varibles.\"\"\"\n",
    "        self.path = '/afs/inf.ed.ac.uk/user/s16/s1690903/share/cov19_2/'\n",
    "        self.text = processed_text\n",
    "        self.topic_num = topic_num\n",
    "        self.alpha = alpha\n",
    "        self.eta = eta\n",
    "\n",
    "    def get_lda_score_eval(self, dictionary, bow_corpus):\n",
    "        \"\"\"LDA model and coherence score.\"\"\"\n",
    "\n",
    "        lda_model = gensim.models.ldamodel.LdaModel(bow_corpus, num_topics=self.topic_num, id2word=dictionary, passes=10,  update_every=1, random_state = 300, alpha=self.alpha, eta=self.eta)\n",
    "        #pprint(lda_model.print_topics())\n",
    "\n",
    "        # get coherence score\n",
    "        cm = CoherenceModel(model=lda_model, corpus=bow_corpus, coherence='u_mass')\n",
    "        coherence = cm.get_coherence()\n",
    "        print('coherence score is {}'.format(coherence))\n",
    "\n",
    "        return lda_model, coherence\n",
    "\n",
    "    def get_score_dict(self, bow_corpus, lda_model_object):\n",
    "        \"\"\"\n",
    "        get lda score for each document\n",
    "        \"\"\"\n",
    "        all_lda_score = {}\n",
    "        for i in range(len(bow_corpus)):\n",
    "            lda_score ={}\n",
    "            for index, score in sorted(lda_model_object[bow_corpus[i]], key=lambda tup: -1*tup[1]):\n",
    "                lda_score[index] = score\n",
    "                od = collections.OrderedDict(sorted(lda_score.items()))\n",
    "            all_lda_score[i] = od\n",
    "        return all_lda_score\n",
    "\n",
    "\n",
    "    def topic_modeling(self):\n",
    "        \"\"\"Get LDA topic modeling.\"\"\"\n",
    "        # generate dictionary\n",
    "        dictionary = gensim.corpora.Dictionary(self.text.values())\n",
    "        bow_corpus = [dictionary.doc2bow(doc) for doc in self.text.values()]\n",
    "        # modeling\n",
    "        model, coherence = self.get_lda_score_eval(dictionary, bow_corpus)\n",
    "\n",
    "        lda_score_all = self.get_score_dict(bow_corpus, model)\n",
    "\n",
    "        all_lda_score_df = pd.DataFrame.from_dict(lda_score_all)\n",
    "        all_lda_score_dfT = all_lda_score_df.T\n",
    "        all_lda_score_dfT = all_lda_score_dfT.fillna(0)\n",
    "\n",
    "        return model, coherence, all_lda_score_dfT\n",
    "\n",
    "    def get_ids_from_selected(self, text):\n",
    "        \"\"\"Get unique id from text \"\"\"\n",
    "        id_l = []\n",
    "        for k, v in text.items():\n",
    "            id_l.append(k)\n",
    "            \n",
    "        return id_l\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select document (abstract/ article body) according to search result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatchArticleBody:\n",
    "    def __init__(self, path, selected_id):\n",
    "        \"\"\"Define varibles.\"\"\"\n",
    "        self.path = path\n",
    "        self.selected_id = selected_id\n",
    "\n",
    "\n",
    "    def read_folder(self):\n",
    "        \"\"\"\n",
    "        Creates a nested dictionary that represents the folder structure of rootdir\n",
    "        \"\"\"\n",
    "        rootdir = self.path.rstrip(os.sep)\n",
    "\n",
    "        article_dict = {}\n",
    "        for path, dirs, files in os.walk(rootdir):\n",
    "            for f in files:\n",
    "                file_id = f.split('.')[0]\n",
    "                #print(file_id)\n",
    "                try:\n",
    "                # load json file according to id\n",
    "                    with open(self.path + f) as f:\n",
    "                        data = json.load(f)\n",
    "                except:\n",
    "                    pass\n",
    "                article_dict[file_id] = data\n",
    "\n",
    "        return article_dict\n",
    "\n",
    "\n",
    "    def extract_bodytext(self):\n",
    "        \"\"\"Unpack nested dictionary and extract body of the article\"\"\"\n",
    "        body = {}\n",
    "        article_dict = self.read_folder()\n",
    "        for k, v in article_dict.items():\n",
    "            strings = ''\n",
    "            prevString = ''\n",
    "            for entry in v['body_text']:\n",
    "                strings = strings + prevString\n",
    "                prevString = entry['text']\n",
    "\n",
    "            body[k] = strings\n",
    "        return body\n",
    "\n",
    "\n",
    "    def get_title_by_bodykv(self, article_dict, keyword):\n",
    "        \"\"\"Search keyword in article body and return title\"\"\"\n",
    "\n",
    "        article_dict = self.read_folder()\n",
    "        selected_id = self.extract_id_list()\n",
    "\n",
    "        result = {}\n",
    "        for k, v in article_dict.items():\n",
    "            for entry in v['body_text']:\n",
    "                if (keyword in entry['text'].split()) and (k in selected_id):\n",
    "                    result[k] = v['metadata']['title']\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "    def extract_id_list(self):\n",
    "        \"\"\"Extract ids from the selected text. \"\"\"\n",
    "        selected_id = []\n",
    "        for k, v in self.selected_id.items():\n",
    "            selected_id.append(str(v['sha']).split(';')[0])\n",
    "            try:\n",
    "                selected_id.append(str(v['sha']).split(';')[1])\n",
    "                selected_id.append(str(v['sha']).split(';')[2])\n",
    "                selected_id.append(str(v['sha']).split(';')[3])\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        return selected_id\n",
    "\n",
    "\n",
    "    def select_text_w_id(self):\n",
    "        body_text = self.extract_bodytext()\n",
    "        selected_id = self.extract_id_list()\n",
    "        selected_text = {}\n",
    "        for k, v in body_text.items():\n",
    "            if k in selected_id:\n",
    "                selected_text[k] = v\n",
    "        return selected_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we extract articles contain the most relevant topic\n",
    "\n",
    "def selected_best_LDA(keyword, varname):\n",
    "        \"\"\"Select the best lda model with extracted text \"\"\"\n",
    "        # convert data to dictionary format\n",
    "        m = MetaData()\n",
    "        metaDict = m.data_dict()\n",
    "\n",
    "        #process text and extract text with keywords\n",
    "        et = ExtractText(metaDict, keyword, varname)\n",
    "        text1 = et.extract_w_keywords()\n",
    "\n",
    "\n",
    "        # extract nouns, verbs and adjetives\n",
    "        text = et.get_noun_verb2(text1)\n",
    "\n",
    "        # optimized alpha and beta\n",
    "        alpha = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "        beta = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "        mydict = lambda: defaultdict(mydict)\n",
    "        cohere_dict = mydict()\n",
    "        for a in alpha:\n",
    "            for b in beta:\n",
    "                lda = LDATopic(text, 20, a, b)\n",
    "                model, coherence, scores = lda.topic_modeling()\n",
    "                cohere_dict[coherence]['a'] = a\n",
    "                cohere_dict[coherence]['b'] = b\n",
    "    \n",
    "        # sort result dictionary to identify the best a, b\n",
    "        # select a,b with the largest coherence score \n",
    "        sort = sorted(cohere_dict.keys())[0] \n",
    "        a = cohere_dict[sort]['a']\n",
    "        b = cohere_dict[sort]['b']\n",
    "        \n",
    "        # run LDA with the optimized values\n",
    "        lda = LDATopic(text, 20, a, b)\n",
    "        model, coherence, scores_best = lda.topic_modeling()\n",
    "        pprint(model.print_topics())\n",
    "\n",
    "        # select merge ids with the LDA topic scores\n",
    "        id_l = lda.get_ids_from_selected(text)\n",
    "        scores_best['cord_uid'] = id_l\n",
    "\n",
    "        return scores_best\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def select_text_from_LDA_results(keyword, varname, scores_best, topic_num):\n",
    "        # choose papers with the most relevant topic\n",
    "        # convert data to dictionary format\n",
    "        m = MetaData()\n",
    "        metaDict = m.data_dict()\n",
    "\n",
    "        # process text and extract text with keywords\n",
    "        et = ExtractText(metaDict, keyword, varname)\n",
    "        # extract text together with punctuation\n",
    "        text1 = et.extract_w_keywords_punc()\n",
    "        # need to decide which topic to choose after training\n",
    "        sel = scores_best[scores_best[topic_num] > 0] \n",
    "        \n",
    "\n",
    "        mydict = lambda: defaultdict(mydict)\n",
    "        selected = mydict()\n",
    "        for k, v in text1.items():\n",
    "            if k in sel.cord_uid.tolist():\n",
    "                selected[k]['title'] = v['title']\n",
    "                selected[k]['processed_text'] = v['processed_text']\n",
    "                selected[k]['sha'] = v['sha']\n",
    "    \n",
    "        return selected\n",
    "\n",
    "def extract_relevant_sentences(cor_dict, search_keywords):\n",
    "    \"\"\"Extract sentences contain keyword in relevant articles. \"\"\"\n",
    "\n",
    "    mydict = lambda: defaultdict(mydict)\n",
    "    sel_sentence = mydict()\n",
    "    \n",
    "    for k, v in cor_dict.items():\n",
    "        keyword_sentence = []\n",
    "        sentences = v['processed_text'].split('.')\n",
    "        for sentence in sentences:\n",
    "            # for each sentence, check if keyword exist\n",
    "            # append sentences contain keyword to list\n",
    "            keyword_sum = sum(1 for word in search_keywords if word in sentence)\n",
    "            if keyword_sum > 0:\n",
    "                keyword_sentence.append(sentence)         \n",
    "\n",
    "        # store results\n",
    "        if not keyword_sentence:\n",
    "            pass\n",
    "        else:\n",
    "            sel_sentence[k]['sentences'] = keyword_sentence\n",
    "            sel_sentence[k]['sha'] = v['sha']\n",
    "            sel_sentence[k]['title'] = v['title']\n",
    "    print('{} articles are relevant to the topic you choose'.format(len(sel_sentence)))\n",
    "\n",
    "    path = '/afs/inf.ed.ac.uk/user/s16/s1690903/share/cov19_2/'\n",
    "    df = pd.DataFrame.from_dict(sel_sentence, orient='index')\n",
    "    df.to_csv(path + 'search_results_{}.csv'.format(search_keywords))\n",
    "    sel_sentence_df = pd.read_csv(path + 'search_results_{}.csv'.format(search_keywords))\n",
    "    return sel_sentence, sel_sentence_df\n",
    "\n",
    "def extract_relevant_sentences2(cor_dict, search_keywords):\n",
    "    \"\"\"Extract sentences contain keyword in relevant articles. \"\"\"\n",
    "\n",
    "    mydict = lambda: defaultdict(mydict)\n",
    "    sel_sentence = mydict()\n",
    "    \n",
    "    for k, v in cor_dict.items():\n",
    "        keyword_sentence = []\n",
    "        sentences = v['processed_text'].split('.')\n",
    "        for sentence in sentences:\n",
    "            # for each sentence, check if keyword exist\n",
    "            # append sentences contain keyword to list\n",
    "            keyword_sum = sum(1 for word in search_keywords if word in sentence)\n",
    "            if keyword_sum > 0:\n",
    "                keyword_sentence.append(sentence)         \n",
    "\n",
    "        # store results\n",
    "        if not keyword_sentence:\n",
    "            pass\n",
    "        else:\n",
    "            sel_sentence[k]['sentences'] = keyword_sentence\n",
    "            sel_sentence[k]['sha'] = v['sha']\n",
    "            sel_sentence[k]['title'] = v['title']\n",
    "    print('{} articles contain keyword {}'.format(len(sel_sentence),  search_keywords))\n",
    "\n",
    "    path = '/afs/inf.ed.ac.uk/user/s16/s1690903/share/cov19_2/eval/'\n",
    "    df = pd.DataFrame.from_dict(sel_sentence, orient='index')\n",
    "    df.to_csv(path + 'eval_results_{}.csv'.format(search_keywords))\n",
    "    sel_sentence_df = pd.read_csv(path + 'eval_results_{}.csv'.format(search_keywords))\n",
    "    return sel_sentence, sel_sentence_df\n",
    "\n",
    "\n",
    "def evaluation(keyword, varname, search_keywords):\n",
    "        #process text and extract text with keywords\n",
    "        m = MetaData()\n",
    "        metaDict = m.data_dict()\n",
    "        et = ExtractText(metaDict, keyword, varname)\n",
    "        text1 = et.extract_w_keywords_punc()\n",
    "        \n",
    "        sel_sentence, sel_sentence_df = extract_relevant_sentences2(text1, search_keywords)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Is wearing mask an effective way to control pandemic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coherence score is -4.336722639525242\n",
      "coherence score is -3.9010410239440367\n",
      "coherence score is -4.389157036678158\n",
      "coherence score is -4.585109650895275\n",
      "coherence score is -4.658858479495897\n",
      "coherence score is -4.181983373771045\n",
      "coherence score is -3.8225572164182773\n",
      "coherence score is -4.115948791902841\n",
      "coherence score is -4.405996653207033\n",
      "coherence score is -4.893575872869723\n",
      "coherence score is -3.763406611071013\n",
      "coherence score is -4.054636612549744\n",
      "coherence score is -3.974976478023649\n",
      "coherence score is -3.605098511028769\n",
      "coherence score is -3.218469889363284\n",
      "coherence score is -3.922771443759005\n",
      "coherence score is -4.56961216145051\n",
      "coherence score is -2.9539869626024027\n",
      "coherence score is -3.2776086868166603\n",
      "coherence score is -3.6310570980589993\n",
      "coherence score is -3.8129640801122164\n",
      "coherence score is -3.7657510362336026\n",
      "coherence score is -3.4720471247415454\n",
      "coherence score is -3.0704332896336615\n",
      "coherence score is -2.990024667297296\n",
      "coherence score is -4.893575872869723\n",
      "[(0,\n",
      "  '0.012*\"patient\" + 0.009*\"use\" + 0.009*\"recommend\" + 0.008*\"mask\" + '\n",
      "  '0.007*\"ventil\" + 0.006*\"acute\" + 0.005*\"respiratory\" + 0.004*\"failur\" + '\n",
      "  '0.004*\"niv\" + 0.003*\"intub\"'),\n",
      " (1,\n",
      "  '0.010*\"mask\" + 0.007*\"public\" + 0.007*\"infect\" + 0.006*\"use\" + 0.006*\"wear\" '\n",
      "  '+ 0.005*\"studi\" + 0.005*\"measur\" + 0.005*\"face\" + 0.005*\"behavior\" + '\n",
      "  '0.005*\"health\"'),\n",
      " (2,\n",
      "  '0.004*\"particl\" + 0.003*\"valu\" + 0.003*\"penetr\" + 0.003*\"size\" + '\n",
      "  '0.003*\"filter\" + 0.002*\"mask\" + 0.002*\"leak\" + 0.002*\"gauz\" + 0.002*\"model\" '\n",
      "  '+ 0.002*\"method\"'),\n",
      " (3,\n",
      "  '0.003*\"epitop\" + 0.002*\"protect\" + 0.002*\"vaccin\" + 0.002*\"skin\" + '\n",
      "  '0.001*\"immunogen\" + 0.001*\"neutral\" + 0.001*\"membran\" + 0.001*\"mucous\" + '\n",
      "  '0.001*\"design\" + 0.001*\"immune\"'),\n",
      " (4,\n",
      "  '0.004*\"viral\" + 0.003*\"psychological\" + 0.003*\"citi\" + 0.002*\"data\" + '\n",
      "  '0.002*\"such\" + 0.002*\"human\" + 0.002*\"impact\" + 0.002*\"virus\" + '\n",
      "  '0.002*\"sampl\" + 0.002*\"anxieti\"'),\n",
      " (5,\n",
      "  '0.011*\"mask\" + 0.008*\"air\" + 0.007*\"exhal\" + 0.006*\"cough\" + 0.005*\"oxygen\" '\n",
      "  '+ 0.005*\"smoke\" + 0.005*\"dispers\" + 0.004*\"patient\" + 0.004*\"leakag\" + '\n",
      "  '0.004*\"plume\"'),\n",
      " (6,\n",
      "  '0.026*\"mask\" + 0.010*\"infect\" + 0.009*\"use\" + 0.007*\"respir\" + '\n",
      "  '0.007*\"group\" + 0.007*\"respiratory\" + 0.006*\"protect\" + 0.005*\"medical\" + '\n",
      "  '0.005*\"control\" + 0.005*\"test\"'),\n",
      " (7,\n",
      "  '0.002*\"activ\" + 0.002*\"properti\" + 0.002*\"eo\" + 0.001*\"antimicrobial\" + '\n",
      "  '0.001*\"tgev\" + 0.001*\"acid\" + 0.001*\"mutant\" + 0.001*\"bind\" + '\n",
      "  '0.001*\"hemagglutin\" + 0.001*\"sialic\"'),\n",
      " (8,\n",
      "  '0.000*\"mask\" + 0.000*\"use\" + 0.000*\"air\" + 0.000*\"place\" + 0.000*\"acute\" + '\n",
      "  '0.000*\"patient\" + 0.000*\"travel\" + 0.000*\"respiratory\" + 0.000*\"studi\" + '\n",
      "  '0.000*\"infect\"'),\n",
      " (9,\n",
      "  '0.018*\"mask\" + 0.018*\"use\" + 0.013*\"patient\" + 0.011*\"infect\" + '\n",
      "  '0.009*\"respiratory\" + 0.006*\"measur\" + 0.006*\"transmiss\" + 0.006*\"studi\" + '\n",
      "  '0.006*\"care\" + 0.006*\"risk\"'),\n",
      " (10,\n",
      "  '0.016*\"air\" + 0.008*\"use\" + 0.007*\"cleaner\" + 0.006*\"inroom\" + 0.006*\"room\" '\n",
      "  '+ 0.005*\"technolog\" + 0.005*\"hepa\" + 0.005*\"infectious\" + 0.004*\"airborne\" '\n",
      "  '+ 0.004*\"uvgi\"'),\n",
      " (11,\n",
      "  '0.004*\"view\" + 0.003*\"obstruct\" + 0.002*\"assess\" + 0.001*\"level\" + '\n",
      "  '0.001*\"paramet\" + 0.001*\"simple\" + 0.001*\"sky\" + 0.001*\"premium\" + '\n",
      "  '0.001*\"unobstructed\" + 0.001*\"residential\"'),\n",
      " (12,\n",
      "  '0.003*\"model\" + 0.002*\"rat\" + 0.001*\"estim\" + 0.001*\"weight\" + 0.001*\"mice\" '\n",
      "  '+ 0.001*\"forecast\" + 0.001*\"encephalitis\" + 0.001*\"paramet\" + 0.001*\"error\" '\n",
      "  '+ 0.001*\"casepati\"'),\n",
      " (13,\n",
      "  '0.000*\"studi\" + 0.000*\"use\" + 0.000*\"mask\" + 0.000*\"capit\" + 0.000*\"social\" '\n",
      "  '+ 0.000*\"discoveri\" + 0.000*\"potential\" + 0.000*\"measur\" + 0.000*\"link\" + '\n",
      "  '0.000*\"reduc\"'),\n",
      " (14,\n",
      "  '0.005*\"household\" + 0.003*\"emerg\" + 0.003*\"prepared\" + 0.003*\"patient\" + '\n",
      "  '0.003*\"meningococcal\" + 0.002*\"wear\" + 0.002*\"adjust\" + 0.002*\"doctor\" + '\n",
      "  '0.002*\"consult\" + 0.002*\"primary\"'),\n",
      " (15,\n",
      "  '0.004*\"filter\" + 0.001*\"untreated\" + 0.001*\"surviv\" + 0.001*\"relative\" + '\n",
      "  '0.001*\"treat\" + 0.001*\"dialdehyd\" + 0.001*\"biocid\" + 0.001*\"inactiv\" + '\n",
      "  '0.001*\"viable\" + 0.001*\"effici\"'),\n",
      " (16,\n",
      "  '0.005*\"antibodi\" + 0.004*\"protein\" + 0.002*\"neutral\" + 0.002*\"sampl\" + '\n",
      "  '0.002*\"serum\" + 0.002*\"region\" + 0.002*\"antigen\" + 0.002*\"domain\" + '\n",
      "  '0.002*\"show\" + 0.002*\"immun\"'),\n",
      " (17,\n",
      "  '0.002*\"symptom\" + 0.002*\"physical\" + 0.002*\"flow\" + 0.002*\"stress\" + '\n",
      "  '0.002*\"psychological\" + 0.001*\"haze\" + 0.001*\"techniqu\" + 0.001*\"score\" + '\n",
      "  '0.001*\"total\" + 0.001*\"role\"'),\n",
      " (18,\n",
      "  '0.000*\"mask\" + 0.000*\"use\" + 0.000*\"infectious\" + 0.000*\"studi\" + '\n",
      "  '0.000*\"result\" + 0.000*\"measur\" + 0.000*\"method\" + 0.000*\"filter\" + '\n",
      "  '0.000*\"respiratory\" + 0.000*\"air\"'),\n",
      " (19,\n",
      "  '0.007*\"intervent\" + 0.006*\"studi\" + 0.005*\"influenza\" + 0.005*\"infect\" + '\n",
      "  '0.004*\"use\" + 0.004*\"contig\" + 0.004*\"rpe\" + 0.003*\"haplotyp\" + '\n",
      "  '0.003*\"data\" + 0.003*\"pandemic\"')]\n"
     ]
    }
   ],
   "source": [
    "#here we select the LDA model with the lowe\n",
    "scores_best_mask = selected_best_LDA('mask', 'abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170, 21)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_best_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe topic No. 1 is most relevant to public wearing mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 40 abstracts selected\n"
     ]
    }
   ],
   "source": [
    "# topic number 1 is most relevant to public wearing mask\n",
    "# which topic do you think is most relevant to your search\n",
    "cor_dict_mask = select_text_from_LDA_results('mask', 'abstract', scores_best_mask, 1)\n",
    "print (\"There are {} abstracts selected\". format(len(cor_dict_mask)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 articles are relevant to the topic you choose\n"
     ]
    }
   ],
   "source": [
    "# extract relevant sentences  #search keywords can be a list\n",
    "sel_sentence_mask, sel_sentence_df_mask = extract_relevant_sentences(cor_dict_mask, ['mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentences</th>\n",
       "      <th>sha</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8o3l3rsf</td>\n",
       "      <td>[', escalatory quarantine, mask wearing when g...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Effectiveness of control strategies for Corona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1mu1z4xd</td>\n",
       "      <td>[' Wearing a mask when going out and avoiding ...</td>\n",
       "      <td>5bb89950ec5a06e2b7f69b2a9c4213dda19b1ab0</td>\n",
       "      <td>Prediction of New Coronavirus Infection Based ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kkpaovhh</td>\n",
       "      <td>[' For symptomatic, unconfirmed patients, doct...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Covid-19: What’s the current advice for UK doc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ht88wu6s</td>\n",
       "      <td>[' CONCLUSION: To early end of the COVID-19 ep...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Estimating the reproductive number and the out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>le0ogx1s</td>\n",
       "      <td>[\"The army of the men of death, in John Bunyan...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A new recruit for the army of the men of death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nzh87aux</td>\n",
       "      <td>[' On the other hand, the model predicts that ...</td>\n",
       "      <td>9b7a0ad7b6c7f59e7a6cf1dc9d07912a273d19b5</td>\n",
       "      <td>The Waiting Time for Inter-Country Spread of P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>n2r4pzan</td>\n",
       "      <td>[', wearing face mask in public venues (73', '...</td>\n",
       "      <td>b7c8e73cf095e30552a32cea04a398331c55ab41</td>\n",
       "      <td>Anticipated and current preventive behaviors i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ywb9krdp</td>\n",
       "      <td>['2%), and wear a face mask (59']</td>\n",
       "      <td>16627f4c7134394da448b1417a771d13ad7cca4a</td>\n",
       "      <td>Pandemic influenza in Australia: Using telepho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bhnh2dq4</td>\n",
       "      <td>[' If an infected person will not use a mask a...</td>\n",
       "      <td>bb9f6cef633c9baf595daae5166b11f88c1271cb</td>\n",
       "      <td>Risk of transmission of airborne infection dur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>49xvz389</td>\n",
       "      <td>['3%) were carrying out one of prevention meas...</td>\n",
       "      <td>545def8771357b4cb2875f5795a0760e97534cc9</td>\n",
       "      <td>Knowledge and attitudes of university students...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0                                          sentences  \\\n",
       "0   8o3l3rsf  [', escalatory quarantine, mask wearing when g...   \n",
       "1   1mu1z4xd  [' Wearing a mask when going out and avoiding ...   \n",
       "2   kkpaovhh  [' For symptomatic, unconfirmed patients, doct...   \n",
       "3   ht88wu6s  [' CONCLUSION: To early end of the COVID-19 ep...   \n",
       "4   le0ogx1s  [\"The army of the men of death, in John Bunyan...   \n",
       "5   nzh87aux  [' On the other hand, the model predicts that ...   \n",
       "6   n2r4pzan  [', wearing face mask in public venues (73', '...   \n",
       "7   ywb9krdp                  ['2%), and wear a face mask (59']   \n",
       "8   bhnh2dq4  [' If an infected person will not use a mask a...   \n",
       "9   49xvz389  ['3%) were carrying out one of prevention meas...   \n",
       "\n",
       "                                        sha  \\\n",
       "0                                       NaN   \n",
       "1  5bb89950ec5a06e2b7f69b2a9c4213dda19b1ab0   \n",
       "2                                       NaN   \n",
       "3                                       NaN   \n",
       "4                                       NaN   \n",
       "5  9b7a0ad7b6c7f59e7a6cf1dc9d07912a273d19b5   \n",
       "6  b7c8e73cf095e30552a32cea04a398331c55ab41   \n",
       "7  16627f4c7134394da448b1417a771d13ad7cca4a   \n",
       "8  bb9f6cef633c9baf595daae5166b11f88c1271cb   \n",
       "9  545def8771357b4cb2875f5795a0760e97534cc9   \n",
       "\n",
       "                                               title  \n",
       "0  Effectiveness of control strategies for Corona...  \n",
       "1  Prediction of New Coronavirus Infection Based ...  \n",
       "2  Covid-19: What’s the current advice for UK doc...  \n",
       "3  Estimating the reproductive number and the out...  \n",
       "4     A new recruit for the army of the men of death  \n",
       "5  The Waiting Time for Inter-Country Spread of P...  \n",
       "6  Anticipated and current preventive behaviors i...  \n",
       "7  Pandemic influenza in Australia: Using telepho...  \n",
       "8  Risk of transmission of airborne infection dur...  \n",
       "9  Knowledge and attitudes of university students...  "
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read extracted article\n",
    "sel_sentence_df_mask.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotation guidline for question 1\n",
    "We extracted 33 papers that are supposed to discuss whether using masks is useful. We annotate  whether the key sentences suggest using mask can reduce the risk of infection.\n",
    "\n",
    "#### Stance Annotation \n",
    "* ‘1’ sentences that support using a mask during a pandemic is useful \n",
    "* ‘2’  papers that assume masks as useful and examine the public’s willingness to comply the rules,\n",
    "* ’0’ no obvious evidence that shows using mask is protective or the protection is very little\n",
    "* '3' Not relevant to the above stance\n",
    "\n",
    "#### relevance annotation\n",
    "* '1' the result is relevent to the question  \n",
    "* '0' the result is not relevant to the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we need to add the stats analysis \n",
    "path = '/afs/inf.ed.ac.uk/user/s16/s1690903/share/cov19_2/annotation/''\n",
    "annotation_mask = pd.read_csv(path + )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "According to the key sentences in 33 abstract that discuss the topic of public using masks, only one paper suggests that there’s not enough evidence to show that mask is useful.\n",
    "There are 14 papers that suggest their results show using surgical mask during a pandemic is effective in reducing infection\n",
    "14 paper consider public individuals using masks are necessary in reducing risks of being infect, and these paper look at whether the public are willing to comply to the rules. (X papers are from  Hong Kong, based on the region of the first author)\n",
    "5 papers are not relevant to the topic\n",
    "\n",
    "Conclusion:\n",
    "government in some regions advocate using masks as a standard approach to reduce risk of infection, papers in these regions focus on whether people comply to the rules. When some government advocate that there is little evidence show that mask is effective in controlling the pandemic, nearly half of the academic papers from our search result either consider wearing masks as a standard practice that the public show comply, nearly half of the papers found evidence to support that wearing masks is effective in controlling the pandemic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: How long in incubation period? In some region (e.g. China), there’s rumour circulating that the incubation period is longer than 14 days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotation guideline for question 2:\n",
    "\n",
    "#### stance annotation\n",
    "Here we want to identify papers that report a result aligns with the incubation period reported by the governments\n",
    "UK government advocate: 2-14 days, mean 5\n",
    "* ‘1’  same as government advocate \n",
    "* ‘0’  different from what the government\n",
    "*  Not relevant to the question \n",
    "\n",
    "#### relevance annotation\n",
    "* '1' the result is relevent to the question  \n",
    "* '2' the result is not relevant to the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coherence score is -4.402954777107732\n",
      "coherence score is -7.622641764950241\n",
      "coherence score is -9.667138416026404\n",
      "coherence score is -8.840829560303707\n",
      "coherence score is -7.75012700862416\n",
      "coherence score is -4.690846825022652\n",
      "coherence score is -7.537936150644841\n",
      "coherence score is -8.204060613000161\n",
      "coherence score is -7.780107529965858\n",
      "coherence score is -7.243947472108755\n",
      "coherence score is -4.860236911790262\n",
      "coherence score is -6.818539222229658\n",
      "coherence score is -8.020048375633895\n",
      "coherence score is -6.931077713393968\n",
      "coherence score is -6.426623602144103\n",
      "coherence score is -4.8710456253984065\n",
      "coherence score is -6.629118614124333\n",
      "coherence score is -5.956842964386887\n",
      "coherence score is -5.355865377504925\n",
      "coherence score is -4.764257961119005\n",
      "coherence score is -4.585814626682113\n",
      "coherence score is -6.216045484929411\n",
      "coherence score is -5.112704786045706\n",
      "coherence score is -4.641328661092419\n",
      "coherence score is -3.607818546962199\n",
      "coherence score is -9.667138416026404\n",
      "[(0,\n",
      "  '0.029*\"case\" + 0.022*\"patient\" + 0.018*\"period\" + 0.016*\"incub\" + '\n",
      "  '0.016*\"day\" + 0.014*\"infect\" + 0.011*\"covid19\" + 0.009*\"estim\" + '\n",
      "  '0.009*\"transmiss\" + 0.007*\"hospit\"'),\n",
      " (1,\n",
      "  '0.002*\"educ\" + 0.002*\"crisi\" + 0.002*\"unit\" + 0.002*\"peopl\" + 0.002*\"prbc\" '\n",
      "  '+ 0.002*\"phtr\" + 0.001*\"impact\" + 0.001*\"c\" + 0.001*\"viru\" + '\n",
      "  '0.001*\"phosphatidylcholin\"'),\n",
      " (2,\n",
      "  '0.005*\"patient\" + 0.004*\"model\" + 0.004*\"case\" + 0.004*\"group\" + '\n",
      "  '0.003*\"incid\" + 0.003*\"student\" + 0.003*\"pain\" + 0.002*\"function\" + '\n",
      "  '0.002*\"time\" + 0.002*\"steroid\"'),\n",
      " (3,\n",
      "  '0.009*\"infect\" + 0.003*\"viru\" + 0.003*\"product\" + 0.003*\"p\" + '\n",
      "  '0.003*\"laboratori\" + 0.002*\"process\" + 0.002*\"incub\" + 0.002*\"sperm\" + '\n",
      "  '0.002*\"viral\" + 0.002*\"case\"'),\n",
      " (4,\n",
      "  '0.003*\"camel\" + 0.003*\"macaqu\" + 0.002*\"baboon\" + 0.002*\"cultur\" + '\n",
      "  '0.002*\"tissu\" + 0.002*\"explant\" + 0.002*\"penetr\" + 0.002*\"shfv\" + '\n",
      "  '0.002*\"merscov\" + 0.002*\"ferret\"'),\n",
      " (5,\n",
      "  '0.002*\"bacteria\" + 0.002*\"intestinal\" + 0.001*\"metabol\" + 0.001*\"metabolit\" '\n",
      "  '+ 0.001*\"saprophyt\" + 0.001*\"juic\" + 0.001*\"gastrointestinal\" + '\n",
      "  '0.001*\"trip\" + 0.001*\"parasit\" + 0.001*\"anticomplementary\"'),\n",
      " (6,\n",
      "  '0.002*\"mhv\" + 0.002*\"room\" + 0.001*\"pathway\" + 0.001*\"instrument\" + '\n",
      "  '0.001*\"dental\" + 0.001*\"ah7n9\" + 0.001*\"secretori\" + 0.001*\"constitutive\" + '\n",
      "  '0.001*\"highspe\" + 0.001*\"rotat\"'),\n",
      " (7,\n",
      "  '0.002*\"hotel\" + 0.002*\"environ\" + 0.001*\"industri\" + 0.001*\"nanocomplex\" + '\n",
      "  '0.001*\"formul\" + 0.001*\"surfac\" + 0.001*\"prepared\" + 0.001*\"vaginal\" + '\n",
      "  '0.001*\"plan\" + 0.001*\"disast\"'),\n",
      " (8,\n",
      "  '0.004*\"activ\" + 0.003*\"peptid\" + 0.002*\"chicken\" + 0.002*\"nkcell\" + '\n",
      "  '0.002*\"somni\" + 0.002*\"hcovoc43\" + 0.002*\"oxid\" + 0.002*\"accumul\" + '\n",
      "  '0.002*\"bovine\" + 0.001*\"astrocyt\"'),\n",
      " (9,\n",
      "  '0.003*\"delay\" + 0.002*\"system\" + 0.001*\"nonautonomous\" + 0.001*\"pattern\" + '\n",
      "  '0.001*\"spatial\" + 0.001*\"lyapunov\" + 0.001*\"chaotic\" + 0.001*\"perman\" + '\n",
      "  '0.001*\"numerical\" + 0.001*\"ture\"'),\n",
      " (10,\n",
      "  '0.027*\"cell\" + 0.019*\"protein\" + 0.009*\"express\" + 0.009*\"viru\" + '\n",
      "  '0.008*\"incub\" + 0.007*\"infect\" + 0.006*\"viral\" + 0.006*\"receptor\" + '\n",
      "  '0.005*\"bind\" + 0.005*\"activ\"'),\n",
      " (11,\n",
      "  '0.009*\"diseas\" + 0.008*\"viru\" + 0.007*\"infect\" + 0.007*\"transmiss\" + '\n",
      "  '0.007*\"incub\" + 0.006*\"outbreak\" + 0.006*\"studi\" + 0.006*\"use\" + '\n",
      "  '0.005*\"case\" + 0.005*\"caus\"'),\n",
      " (12,\n",
      "  '0.002*\"t\" + 0.002*\"apical\" + 0.002*\"protein\" + 0.002*\"polypeptid\" + '\n",
      "  '0.002*\"basolateral\" + 0.002*\"cell\" + 0.002*\"mice\" + 0.002*\"supernat\" + '\n",
      "  '0.002*\"memori\" + 0.001*\"purif\"'),\n",
      " (13,\n",
      "  '0.001*\"airborne\" + 0.001*\"indoor\" + 0.000*\"occup\" + '\n",
      "  '0.000*\"shortincubationperiod\" + 0.000*\"environ\" + 0.000*\"theoretical\" + '\n",
      "  '0.000*\"room\" + 0.000*\"ventil\" + 0.000*\"feather\" + 0.000*\"zoonos\"'),\n",
      " (14,\n",
      "  '0.003*\"parasit\" + 0.002*\"prolifer\" + 0.002*\"idv\" + 0.002*\"lymphocyt\" + '\n",
      "  '0.002*\"rat\" + 0.001*\"transcript\" + 0.001*\"nigra\" + 0.001*\"erythrocyt\" + '\n",
      "  '0.001*\"brain\" + 0.001*\"popul\"'),\n",
      " (15,\n",
      "  '0.014*\"cell\" + 0.011*\"viru\" + 0.006*\"activ\" + 0.004*\"ace2\" + 0.004*\"incub\" '\n",
      "  '+ 0.004*\"shed\" + 0.004*\"express\" + 0.004*\"inhibitor\" + 0.004*\"infect\" + '\n",
      "  '0.003*\"cftr\"'),\n",
      " (16,\n",
      "  '0.005*\"cell\" + 0.003*\"strain\" + 0.003*\"insulin\" + 0.002*\"hpev1\" + '\n",
      "  '0.002*\"endothelial\" + 0.002*\"peptid\" + 0.002*\"recombinant\" + 0.002*\"virus\" '\n",
      "  '+ 0.002*\"fibril\" + 0.002*\"result\"'),\n",
      " (17,\n",
      "  '0.014*\"infect\" + 0.013*\"cell\" + 0.013*\"viru\" + 0.013*\"incub\" + 0.009*\"use\" '\n",
      "  '+ 0.009*\"detect\" + 0.007*\"result\" + 0.007*\"viral\" + 0.006*\"studi\" + '\n",
      "  '0.006*\"diseas\"'),\n",
      " (18,\n",
      "  '0.002*\"cadmium\" + 0.002*\"calv\" + 0.002*\"salmonella\" + 0.002*\"student\" + '\n",
      "  '0.002*\"cdcl2\" + 0.001*\"rotaviru\" + 0.001*\"veterinary\" + 0.001*\"preventive\" '\n",
      "  '+ 0.001*\"toxic\" + 0.001*\"excret\"'),\n",
      " (19,\n",
      "  '0.001*\"safeti\" + 0.001*\"airway\" + 0.001*\"rtd1\" + 0.001*\"toler\" + '\n",
      "  '0.001*\"inflamm\" + 0.001*\"bronchial\" + 0.001*\"peptid\" + 0.001*\"stabil\" + '\n",
      "  '0.001*\"therapeutic\" + 0.000*\"α26\"')]\n"
     ]
    }
   ],
   "source": [
    "scores_best_incu = selected_best_LDA('incubation', 'abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 213 abstracts selected\n"
     ]
    }
   ],
   "source": [
    "# topic number 0 is most relevant to public wearing mask\n",
    "# which topic do you think is most relevant to your search\n",
    "cor_dict_incu = select_text_from_LDA_results('incubation', 'abstract', scores_best_incu, 0)\n",
    "print (\"There are {} abstracts selected\". format(len(cor_dict_incu)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124 articles are relevant to the topic you choose\n"
     ]
    }
   ],
   "source": [
    "# extract relevant sentences  #search keywords can be a list\n",
    "sel_sentence_incu, sel_sentence_df_incu = extract_relevant_sentences(cor_dict_incu, ['day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentences</th>\n",
       "      <th>sha</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>h89scli5</td>\n",
       "      <td>[' For monitored individuals, we identified un...</td>\n",
       "      <td>b5161b031c7f720562e94735a018d1c3c8be3ae5</td>\n",
       "      <td>Quantifying the Risk and Cost of Active Monito...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ykofrn9i</td>\n",
       "      <td>[' Our results show that the incubation period...</td>\n",
       "      <td>cbc05d14c57b91081970a232ab83bc993f998fe2</td>\n",
       "      <td>Incubation Period and Other Epidemiological Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u8goc7io</td>\n",
       "      <td>['7, 95% CI) days, ranging from 2', '1 days (2']</td>\n",
       "      <td>12fac9aedb1a09a3922a3c084ce4723708e463d6</td>\n",
       "      <td>The incubation period of 2019-nCoV infections ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vspnuxz9</td>\n",
       "      <td>['0 days (95% credible interval [CrI]: 3', '6 ...</td>\n",
       "      <td>a1bff76ce360e8990b0a4ee2a5228a6e6e63d9c1</td>\n",
       "      <td>Serial interval of novel coronavirus (2019-nCo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ra3t6kmm</td>\n",
       "      <td>['9 days (95% credible interval [CrI], 2 days-...</td>\n",
       "      <td>c85f571a674c7fed0ccb9176e9cf9f3d3659ca32</td>\n",
       "      <td>Analysis of the epidemic growth of the early 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tovfd9lw</td>\n",
       "      <td>['0 days (range, 0 to 24', '0 days)']</td>\n",
       "      <td>dfb0fedbeed56bd2b795a67faab28295afc14c96</td>\n",
       "      <td>Clinical characteristics of 2019 novel coronav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>45g12waw</td>\n",
       "      <td>['4 days, and the R0 value is likely to be bet...</td>\n",
       "      <td>36a5f6d55d7c5f67d4344e36da0a72856ad3dda0</td>\n",
       "      <td>The Novel Coronavirus, 2019-nCoV, is Highly Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rcbw54xc</td>\n",
       "      <td>['5days', ' Cumulation number of patients at t...</td>\n",
       "      <td>57e01ad2a4961cd5cc6a3733f5f8c013a8946f3c</td>\n",
       "      <td>A model simulation study on effects of interve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fmymklz6</td>\n",
       "      <td>[' Incubation time ranged from one to twenty d...</td>\n",
       "      <td>f3ff1ecae96700f41b83d2a034a3a959428388b0</td>\n",
       "      <td>The cross-sectional study of hospitalized coro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dbzrd23n</td>\n",
       "      <td>['6) days and the mean onset-admission interva...</td>\n",
       "      <td>eb8ac60527db35b10881cb4fd86b8a6e21983d02</td>\n",
       "      <td>A descriptive study of the impact of diseases ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0                                          sentences  \\\n",
       "0   h89scli5  [' For monitored individuals, we identified un...   \n",
       "1   ykofrn9i  [' Our results show that the incubation period...   \n",
       "2   u8goc7io   ['7, 95% CI) days, ranging from 2', '1 days (2']   \n",
       "3   vspnuxz9  ['0 days (95% credible interval [CrI]: 3', '6 ...   \n",
       "4   ra3t6kmm  ['9 days (95% credible interval [CrI], 2 days-...   \n",
       "5   tovfd9lw              ['0 days (range, 0 to 24', '0 days)']   \n",
       "6   45g12waw  ['4 days, and the R0 value is likely to be bet...   \n",
       "7   rcbw54xc  ['5days', ' Cumulation number of patients at t...   \n",
       "8   fmymklz6  [' Incubation time ranged from one to twenty d...   \n",
       "9   dbzrd23n  ['6) days and the mean onset-admission interva...   \n",
       "\n",
       "                                        sha  \\\n",
       "0  b5161b031c7f720562e94735a018d1c3c8be3ae5   \n",
       "1  cbc05d14c57b91081970a232ab83bc993f998fe2   \n",
       "2  12fac9aedb1a09a3922a3c084ce4723708e463d6   \n",
       "3  a1bff76ce360e8990b0a4ee2a5228a6e6e63d9c1   \n",
       "4  c85f571a674c7fed0ccb9176e9cf9f3d3659ca32   \n",
       "5  dfb0fedbeed56bd2b795a67faab28295afc14c96   \n",
       "6  36a5f6d55d7c5f67d4344e36da0a72856ad3dda0   \n",
       "7  57e01ad2a4961cd5cc6a3733f5f8c013a8946f3c   \n",
       "8  f3ff1ecae96700f41b83d2a034a3a959428388b0   \n",
       "9  eb8ac60527db35b10881cb4fd86b8a6e21983d02   \n",
       "\n",
       "                                               title  \n",
       "0  Quantifying the Risk and Cost of Active Monito...  \n",
       "1  Incubation Period and Other Epidemiological Ch...  \n",
       "2  The incubation period of 2019-nCoV infections ...  \n",
       "3  Serial interval of novel coronavirus (2019-nCo...  \n",
       "4  Analysis of the epidemic growth of the early 2...  \n",
       "5  Clinical characteristics of 2019 novel coronav...  \n",
       "6  The Novel Coronavirus, 2019-nCoV, is Highly Co...  \n",
       "7  A model simulation study on effects of interve...  \n",
       "8  The cross-sectional study of hospitalized coro...  \n",
       "9  A descriptive study of the impact of diseases ...  "
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read extracted article\n",
    "sel_sentence_df_incu.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Are asymptomatic patients infectious?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotation guideline for question 3:\n",
    "Here we want to identify whether asymtomatic cases contribute to the spread of the virus\n",
    "\n",
    "#### stance annotation\n",
    "* ‘1’  there is clear evidence show that asymtomatic cases contribute to the spread of the virus\n",
    "* ‘0’  it is unlikely that asymtomatic cases contribute to the spread of the virus\n",
    "* '3' Not relevant to the question\n",
    "\n",
    "#### relevance annotation\n",
    "* '1' the result is relevent to the question  \n",
    "* '0' the result is not relevant to the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coherence score is -2.333875362764049\n",
      "coherence score is -4.70447389062267\n",
      "coherence score is -6.939599491635526\n",
      "coherence score is -8.440505363564451\n",
      "coherence score is -9.591134816334584\n",
      "coherence score is -2.2594033960424147\n",
      "coherence score is -5.105876829676597\n",
      "coherence score is -6.9371475741261035\n",
      "coherence score is -8.606789439278637\n",
      "coherence score is -9.453634935286304\n",
      "coherence score is -2.638911020212841\n",
      "coherence score is -4.846954903243043\n",
      "coherence score is -6.8515540183404955\n",
      "coherence score is -8.924401332546264\n",
      "coherence score is -8.268359620682485\n",
      "coherence score is -2.4049378700075303\n",
      "coherence score is -4.651142459964543\n",
      "coherence score is -6.56690398681833\n",
      "coherence score is -7.81408598379605\n",
      "coherence score is -5.9898250531948944\n",
      "coherence score is -2.334124552642998\n",
      "coherence score is -4.078897796588015\n",
      "coherence score is -6.8391754668949485\n",
      "coherence score is -6.1568698549644205\n",
      "coherence score is -4.795885092862488\n",
      "coherence score is -9.591134816334584\n",
      "[(0,\n",
      "  '0.002*\"calv\" + 0.001*\"ioae\" + 0.001*\"stent\" + 0.001*\"graft\" + '\n",
      "  '0.001*\"fenestrated\" + 0.001*\"function\" + 0.001*\"branch\" + 0.001*\"bovin\" + '\n",
      "  '0.001*\"moderate\" + 0.001*\"lung\"'),\n",
      " (1,\n",
      "  '0.000*\"cell\" + 0.000*\"infect\" + 0.000*\"clinical\" + 0.000*\"viru\" + '\n",
      "  '0.000*\"diseas\" + 0.000*\"asymptomatic\" + 0.000*\"macaqu\" + 0.000*\"case\" + '\n",
      "  '0.000*\"allergic\" + 0.000*\"strain\"'),\n",
      " (2,\n",
      "  '0.001*\"yield\" + 0.001*\"biomark\" + 0.001*\"apoa1\" + 0.000*\"alveolar\" + '\n",
      "  '0.000*\"fob\" + 0.000*\"reticular\" + 0.000*\"diagnostic\" + 0.000*\"nodular\" + '\n",
      "  '0.000*\"fulllength\" + 0.000*\"infiltr\"'),\n",
      " (3,\n",
      "  '0.009*\"children\" + 0.008*\"patient\" + 0.008*\"allergic\" + 0.006*\"effect\" + '\n",
      "  '0.005*\"young\" + 0.005*\"case\" + 0.005*\"model\" + 0.004*\"asthma\" + '\n",
      "  '0.004*\"clinical\" + 0.004*\"treatment\"'),\n",
      " (4,\n",
      "  '0.009*\"cell\" + 0.008*\"bat\" + 0.006*\"respons\" + 0.005*\"infect\" + '\n",
      "  '0.004*\"immune\" + 0.004*\"dog\" + 0.004*\"viral\" + 0.003*\"gene\" + '\n",
      "  '0.003*\"protein\" + 0.002*\"macaqu\"'),\n",
      " (5,\n",
      "  '0.002*\"inflamm\" + 0.002*\"intraamniotic\" + 0.001*\"r\" + 0.001*\"piglet\" + '\n",
      "  '0.001*\"estim\" + 0.001*\"day\" + 0.001*\"method\" + 0.001*\"astrovirus\" + '\n",
      "  '0.001*\"oper\" + 0.001*\"cadmium\"'),\n",
      " (6,\n",
      "  '0.001*\"plant\" + 0.001*\"lifestyl\" + 0.000*\"influenza\" + 0.000*\"persistent\" + '\n",
      "  '0.000*\"virus\" + 0.000*\"eukaryotic\" + 0.000*\"partitivirida\" + '\n",
      "  '0.000*\"endornaviru\" + 0.000*\"vast\" + 0.000*\"wellcharacterized\"'),\n",
      " (7,\n",
      "  '0.001*\"ccv\" + 0.001*\"renal\" + 0.001*\"hypouricaemia\" + 0.001*\"urate\" + '\n",
      "  '0.000*\"uric\" + 0.000*\"stone\" + 0.000*\"inherit\" + 0.000*\"urat1\" + '\n",
      "  '0.000*\"cat\" + 0.000*\"handl\"'),\n",
      " (8,\n",
      "  '0.003*\"case\" + 0.001*\"avid\" + 0.001*\"sleep\" + 0.001*\"chest\" + 0.001*\"ct\" + '\n",
      "  '0.001*\"infect\" + 0.001*\"enfant\" + 0.001*\"patient\" + 0.001*\"imag\" + '\n",
      "  '0.001*\"acid\"'),\n",
      " (9,\n",
      "  '0.002*\"cage\" + 0.002*\"dog\" + 0.002*\"ecov\" + 0.002*\"hors\" + 0.001*\"piglet\" + '\n",
      "  '0.001*\"pheasant\" + 0.001*\"pid\" + 0.001*\"swab\" + 0.001*\"infect\" + '\n",
      "  '0.001*\"autoantibodi\"'),\n",
      " (10,\n",
      "  '0.002*\"blockag\" + 0.002*\"traffic\" + 0.001*\"market\" + 0.001*\"wet\" + '\n",
      "  '0.001*\"puuv\" + 0.001*\"quarantin\" + 0.001*\"id99\" + 0.001*\"htnv\" + '\n",
      "  '0.001*\"shrew\" + 0.001*\"hamster\"'),\n",
      " (11,\n",
      "  '0.001*\"mscpv1\" + 0.001*\"env\" + 0.001*\"bat\" + 0.001*\"wild\" + 0.001*\"pfv\" + '\n",
      "  '0.001*\"carnivor\" + 0.001*\"cakov\" + 0.001*\"kobuvirus\" + 0.001*\"gp48tm\" + '\n",
      "  '0.001*\"helic\"'),\n",
      " (12,\n",
      "  '0.001*\"puppi\" + 0.001*\"clean\" + 0.001*\"hcw\" + 0.001*\"rct\" + 0.001*\"pkdl\" + '\n",
      "  '0.001*\"room\" + 0.001*\"cpv\" + 0.001*\"ccov\" + 0.001*\"diarrhoea\" + '\n",
      "  '0.001*\"infector\"'),\n",
      " (13,\n",
      "  '0.001*\"proteas\" + 0.001*\"inhibitor\" + 0.001*\"gut\" + 0.001*\"3cl\" + '\n",
      "  '0.001*\"microbiom\" + 0.001*\"felin\" + 0.001*\"astvinfect\" + 0.000*\"enteric\" + '\n",
      "  '0.000*\"taxa\" + 0.000*\"astv\"'),\n",
      " (14,\n",
      "  '0.001*\"afadr\" + 0.001*\"fshd\" + 0.001*\"cbc\" + 0.001*\"express\" + '\n",
      "  '0.001*\"intestinal\" + 0.001*\"abund\" + 0.001*\"dux4fl\" + 0.001*\"skeletal\" + '\n",
      "  '0.001*\"fshdlike\" + 0.001*\"cytokin\"'),\n",
      " (15,\n",
      "  '0.001*\"student\" + 0.001*\"offspr\" + 0.001*\"tonsil\" + 0.001*\"cmml\" + '\n",
      "  '0.001*\"israeli\" + 0.001*\"obstruct\" + 0.001*\"btv3\" + 0.001*\"reassort\" + '\n",
      "  '0.001*\"bovi\" + 0.001*\"adenoid\"'),\n",
      " (16,\n",
      "  '0.002*\"bat\" + 0.002*\"model\" + 0.002*\"infect\" + 0.002*\"screen\" + '\n",
      "  '0.002*\"dromedari\" + 0.002*\"estim\" + 0.001*\"virus\" + 0.001*\"camel\" + '\n",
      "  '0.001*\"mhc\" + 0.001*\"peptid\"'),\n",
      " (17,\n",
      "  '0.017*\"infect\" + 0.015*\"respiratory\" + 0.014*\"detect\" + 0.013*\"patient\" + '\n",
      "  '0.013*\"asymptomatic\" + 0.012*\"children\" + 0.010*\"viru\" + 0.009*\"studi\" + '\n",
      "  '0.009*\"sampl\" + 0.009*\"virus\"'),\n",
      " (18,\n",
      "  '0.001*\"ipd\" + 0.001*\"mhva59\" + 0.001*\"microbiota\" + 0.001*\"chadox1\" + '\n",
      "  '0.001*\"homozygous\" + 0.000*\"children\" + 0.000*\"f11\" + 0.000*\"immunogen\" + '\n",
      "  '0.000*\"candid\" + 0.000*\"pfu\"'),\n",
      " (19,\n",
      "  '0.025*\"infect\" + 0.014*\"case\" + 0.011*\"asymptomatic\" + 0.011*\"diseas\" + '\n",
      "  '0.010*\"patient\" + 0.010*\"viru\" + 0.008*\"transmiss\" + 0.005*\"viral\" + '\n",
      "  '0.005*\"severe\" + 0.005*\"clinical\"')]\n"
     ]
    }
   ],
   "source": [
    "scores_best_asym = selected_best_LDA('asymptomatic', 'abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 404 abstracts selected\n"
     ]
    }
   ],
   "source": [
    "# topic number 19 is most relevant to public wearing mask\n",
    "# which topic do you think is most relevant to your search\n",
    "cor_dict_asym = select_text_from_LDA_results('asymptomatic', 'abstract', scores_best_asym, 19)\n",
    "print (\"There are {} abstracts selected\". format(len(cor_dict_asym)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143 articles are relevant to the topic you choose\n"
     ]
    }
   ],
   "source": [
    "# extract relevant sentences  #search keywords can be a list\n",
    "sel_sentence_asym, sel_sentence_df_asym = extract_relevant_sentences(cor_dict_asym, ['transmission'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentences</th>\n",
       "      <th>sha</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>3w63yt7f</td>\n",
       "      <td>[' Of the 28 cases, 16 were index cases import...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Early Epidemiological and Clinical Characteris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>ue6e3ua3</td>\n",
       "      <td>[' Dromedary camels, hosts for MERS-CoV, are i...</td>\n",
       "      <td>72076bc07694d7ba7e9fd2adfcb10b11fde1c9ba; 76b7...</td>\n",
       "      <td>Middle East respiratory syndrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>1nhlu89c</td>\n",
       "      <td>[' However, the recent report on asymptomatic ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus disease-2019: is fever an adequate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>kwq2y3il</td>\n",
       "      <td>[' Therefore, there is still a theoretical ris...</td>\n",
       "      <td>a9a4101b25236a4fc0e14a9cbdd904ca8b2baffd</td>\n",
       "      <td>Coronavirus Disease 2019: Coronaviruses and Bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6kuh4njb</td>\n",
       "      <td>[' Conclusion Being able to protect healthcare...</td>\n",
       "      <td>5ec1bf2fc5d286672feb316e70accdd302d7ed50</td>\n",
       "      <td>MERS-CoV infection among healthcare workers an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>k3f7ohzg</td>\n",
       "      <td>[' The measures to prevent transmission was ve...</td>\n",
       "      <td>14dbf1c01f2c422c1aefee32f094cc524ea03af1</td>\n",
       "      <td>Characteristics of COVID-19 infection in Beijing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>kiq6xb6k</td>\n",
       "      <td>[' Interpretation Person-to-person transmissio...</td>\n",
       "      <td>ad0e9c151402df00786e0aa6dd30987004966deb</td>\n",
       "      <td>First known person-to-person transmission of s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>626ch774</td>\n",
       "      <td>['We simulated 100 2019-nCoV infected travelle...</td>\n",
       "      <td>09e25e413faba97b87efc701d1ab8d2a18386efb; 4e55...</td>\n",
       "      <td>Effectiveness of airport screening at detectin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>pth2d40p</td>\n",
       "      <td>[' In addition, nosocomial infection of hospit...</td>\n",
       "      <td>89a8918f7e3044b89642aaa74defc7381abef482; 1f5c...</td>\n",
       "      <td>Asymptomatic carrier state, acute respiratory ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>hfkzu18p</td>\n",
       "      <td>[' Here we highlight nine most important resea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SARS-CoV-2 and COVID-19: The most important re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                          sentences  \\\n",
       "133   3w63yt7f  [' Of the 28 cases, 16 were index cases import...   \n",
       "134   ue6e3ua3  [' Dromedary camels, hosts for MERS-CoV, are i...   \n",
       "135   1nhlu89c  [' However, the recent report on asymptomatic ...   \n",
       "136   kwq2y3il  [' Therefore, there is still a theoretical ris...   \n",
       "137   6kuh4njb  [' Conclusion Being able to protect healthcare...   \n",
       "138   k3f7ohzg  [' The measures to prevent transmission was ve...   \n",
       "139   kiq6xb6k  [' Interpretation Person-to-person transmissio...   \n",
       "140   626ch774  ['We simulated 100 2019-nCoV infected travelle...   \n",
       "141   pth2d40p  [' In addition, nosocomial infection of hospit...   \n",
       "142   hfkzu18p  [' Here we highlight nine most important resea...   \n",
       "\n",
       "                                                   sha  \\\n",
       "133                                                NaN   \n",
       "134  72076bc07694d7ba7e9fd2adfcb10b11fde1c9ba; 76b7...   \n",
       "135                                                NaN   \n",
       "136           a9a4101b25236a4fc0e14a9cbdd904ca8b2baffd   \n",
       "137           5ec1bf2fc5d286672feb316e70accdd302d7ed50   \n",
       "138           14dbf1c01f2c422c1aefee32f094cc524ea03af1   \n",
       "139           ad0e9c151402df00786e0aa6dd30987004966deb   \n",
       "140  09e25e413faba97b87efc701d1ab8d2a18386efb; 4e55...   \n",
       "141  89a8918f7e3044b89642aaa74defc7381abef482; 1f5c...   \n",
       "142                                                NaN   \n",
       "\n",
       "                                                 title  \n",
       "133  Early Epidemiological and Clinical Characteris...  \n",
       "134                   Middle East respiratory syndrome  \n",
       "135  Coronavirus disease-2019: is fever an adequate...  \n",
       "136  Coronavirus Disease 2019: Coronaviruses and Bl...  \n",
       "137  MERS-CoV infection among healthcare workers an...  \n",
       "138   Characteristics of COVID-19 infection in Beijing  \n",
       "139  First known person-to-person transmission of s...  \n",
       "140  Effectiveness of airport screening at detectin...  \n",
       "141  Asymptomatic carrier state, acute respiratory ...  \n",
       "142  SARS-CoV-2 and COVID-19: The most important re...  "
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_sentence_df_asym.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: Will the virus disappear in the summer? \n",
    "\n",
    "### Annotation guideline for question 4\n",
    "* '1' the result is relevent to the question  \n",
    "* '0' the result is not relevant to the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coherence score is -3.0018444354246148\n",
      "coherence score is -3.7713565323755445\n",
      "coherence score is -4.853842927051636\n",
      "coherence score is -5.115316283418001\n",
      "coherence score is -5.275887027502832\n",
      "coherence score is -2.7310261720813687\n",
      "coherence score is -3.365557896859708\n",
      "coherence score is -3.823341883449962\n",
      "coherence score is -4.286592442380965\n",
      "coherence score is -4.657320289835465\n",
      "coherence score is -2.686902420165036\n",
      "coherence score is -3.455505499881666\n",
      "coherence score is -3.4104528813580304\n",
      "coherence score is -3.9792818874763447\n",
      "coherence score is -4.118397656468215\n",
      "coherence score is -2.7034845774008556\n",
      "coherence score is -3.4266148606542437\n",
      "coherence score is -3.2756509301082404\n",
      "coherence score is -3.5675747343801505\n",
      "coherence score is -3.359507266843969\n",
      "coherence score is -2.7106744166911487\n",
      "coherence score is -2.9796069633608218\n",
      "coherence score is -2.9585235165206862\n",
      "coherence score is -3.077832723977046\n",
      "coherence score is -2.9506491538081954\n",
      "coherence score is -5.275887027502832\n",
      "[(0,\n",
      "  '0.024*\"respiratory\" + 0.018*\"infect\" + 0.016*\"season\" + 0.016*\"virus\" + '\n",
      "  '0.015*\"viru\" + 0.013*\"influenza\" + 0.012*\"detect\" + 0.012*\"year\" + '\n",
      "  '0.012*\"studi\" + 0.011*\"children\"'),\n",
      " (1,\n",
      "  '0.002*\"recur\" + 0.001*\"establish\" + 0.001*\"anim\" + 0.001*\"recurr\" + '\n",
      "  '0.001*\"diseas\" + 0.001*\"unpredictable\" + 0.001*\"fragmentary\" + '\n",
      "  '0.001*\"reservoir\" + 0.001*\"physiolog\" + 0.001*\"emergent\"'),\n",
      " (2,\n",
      "  '0.000*\"pathogen\" + 0.000*\"case\" + 0.000*\"dengu\" + 0.000*\"fever\" + '\n",
      "  '0.000*\"screen\" + 0.000*\"infect\" + 0.000*\"model\" + 0.000*\"interact\" + '\n",
      "  '0.000*\"data\" + 0.000*\"use\"'),\n",
      " (3,\n",
      "  '0.007*\"effect\" + 0.007*\"strain\" + 0.005*\"litter\" + 0.005*\"size\" + '\n",
      "  '0.005*\"amplitud\" + 0.004*\"seasonal\" + 0.004*\"explain\" + 0.003*\"use\" + '\n",
      "  '0.003*\"expect\" + 0.003*\"period\"'),\n",
      " (4,\n",
      "  '0.006*\"rabi\" + 0.004*\"model\" + 0.003*\"dog\" + 0.003*\"human\" + '\n",
      "  '0.003*\"interact\" + 0.002*\"simul\" + 0.002*\"section\" + 0.002*\"framework\" + '\n",
      "  '0.002*\"seir\" + 0.002*\"basic\"'),\n",
      " (5,\n",
      "  '0.005*\"travel\" + 0.005*\"influenza\" + 0.004*\"school\" + 0.004*\"spread\" + '\n",
      "  '0.004*\"model\" + 0.003*\"time\" + 0.003*\"entri\" + 0.003*\"air\" + 0.003*\"cohort\" '\n",
      "  '+ 0.003*\"locat\"'),\n",
      " (6,\n",
      "  '0.007*\"exacerb\" + 0.005*\"chang\" + 0.005*\"hand\" + 0.005*\"asthma\" + '\n",
      "  '0.004*\"viral\" + 0.004*\"studi\" + 0.004*\"trigger\" + 0.003*\"factor\" + '\n",
      "  '0.003*\"children\" + 0.003*\"diseas\"'),\n",
      " (7,\n",
      "  '0.005*\"studi\" + 0.003*\"use\" + 0.003*\"data\" + 0.003*\"hpiv\" + 0.003*\"trend\" + '\n",
      "  '0.002*\"behavior\" + 0.002*\"birth\" + 0.002*\"icv\" + 0.002*\"topic\" + '\n",
      "  '0.002*\"type\"'),\n",
      " (8,\n",
      "  '0.003*\"risk\" + 0.003*\"ci\" + 0.003*\"increas\" + 0.003*\"hfmd\" + 0.002*\"incid\" '\n",
      "  '+ 0.002*\"factor\" + 0.002*\"temperatur\" + 0.002*\"rainfal\" + 0.002*\"session\" + '\n",
      "  '0.002*\"mortal\"'),\n",
      " (9,\n",
      "  '0.008*\"diseas\" + 0.005*\"seasonal\" + 0.005*\"incid\" + 0.004*\"control\" + '\n",
      "  '0.003*\"infectious\" + 0.003*\"season\" + 0.003*\"data\" + 0.003*\"state\" + '\n",
      "  '0.003*\"infect\" + 0.003*\"correl\"'),\n",
      " (10,\n",
      "  '0.005*\"diarrhoea\" + 0.003*\"dengu\" + 0.003*\"case\" + 0.002*\"import\" + '\n",
      "  '0.002*\"latitud\" + 0.002*\"meet\" + 0.002*\"progress\" + 0.002*\"fever\" + '\n",
      "  '0.002*\"threat\" + 0.002*\"model\"'),\n",
      " (11,\n",
      "  '0.003*\"model\" + 0.003*\"bovine\" + 0.002*\"estim\" + 0.002*\"locat\" + '\n",
      "  '0.002*\"land\" + 0.002*\"infer\" + 0.002*\"human\" + 0.002*\"equat\" + '\n",
      "  '0.002*\"differential\" + 0.002*\"flux\"'),\n",
      " (12,\n",
      "  '0.002*\"sampl\" + 0.002*\"parvum\" + 0.002*\"concentr\" + 0.002*\"air\" + '\n",
      "  '0.002*\"preval\" + 0.002*\"fecal\" + 0.002*\"calv\" + 0.002*\"diarrheal\" + '\n",
      "  '0.002*\"pollut\" + 0.002*\"urban\"'),\n",
      " (13,\n",
      "  '0.005*\"sequenc\" + 0.002*\"mutat\" + 0.001*\"locat\" + 0.001*\"reemerg\" + '\n",
      "  '0.001*\"migrat\" + 0.001*\"neuraminidas\" + 0.001*\"date\" + 0.001*\"different\" + '\n",
      "  '0.001*\"continu\" + 0.001*\"cluster\"'),\n",
      " (14,\n",
      "  '0.000*\"influenza\" + 0.000*\"virus\" + 0.000*\"season\" + 0.000*\"viru\" + '\n",
      "  '0.000*\"vaccin\" + 0.000*\"infect\" + 0.000*\"respiratory\" + 0.000*\"region\" + '\n",
      "  '0.000*\"rsv\" + 0.000*\"patient\"'),\n",
      " (15,\n",
      "  '0.005*\"infect\" + 0.004*\"influenza\" + 0.004*\"strain\" + 0.003*\"incid\" + '\n",
      "  '0.003*\"isol\" + 0.003*\"respiratory\" + 0.003*\"case\" + 0.003*\"season\" + '\n",
      "  '0.003*\"studi\" + 0.003*\"hcovnl63\"'),\n",
      " (16,\n",
      "  '0.005*\"farm\" + 0.003*\"score\" + 0.003*\"movement\" + 0.002*\"gather\" + '\n",
      "  '0.002*\"select\" + 0.002*\"paramet\" + 0.002*\"individu\" + 0.002*\"speci\" + '\n",
      "  '0.002*\"surveil\" + 0.002*\"propos\"'),\n",
      " (17,\n",
      "  '0.004*\"birth\" + 0.003*\"human\" + 0.003*\"hcovnl63\" + 0.003*\"transmiss\" + '\n",
      "  '0.003*\"mobil\" + 0.002*\"environmental\" + 0.002*\"use\" + 0.002*\"season\" + '\n",
      "  '0.002*\"model\" + 0.002*\"outbreak\"'),\n",
      " (18,\n",
      "  '0.000*\"viral\" + 0.000*\"viru\" + 0.000*\"pneumonia\" + 0.000*\"identifi\" + '\n",
      "  '0.000*\"respiratory\" + 0.000*\"influenza\" + 0.000*\"infect\" + 0.000*\"caus\" + '\n",
      "  '0.000*\"acute\" + 0.000*\"season\"'),\n",
      " (19,\n",
      "  '0.008*\"fli\" + 0.004*\"cpv\" + 0.004*\"facil\" + 0.003*\"number\" + 0.003*\"canin\" '\n",
      "  '+ 0.002*\"negative\" + 0.002*\"captur\" + 0.002*\"locat\" + 0.002*\"statu\" + '\n",
      "  '0.002*\"significant\"')]\n"
     ]
    }
   ],
   "source": [
    "scores_best_sea = selected_best_LDA('seasonality', 'abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 130 abstracts selected\n"
     ]
    }
   ],
   "source": [
    "# topic number 19 is most relevant to publicr wearing mask\n",
    "# which topic do you think is most relevant to your search\n",
    "cor_dict_sea = select_text_from_LDA_results('season', 'abstract', scores_best_sea, 0)\n",
    "print (\"There are {} abstracts selected\". format(len(cor_dict_sea)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 articles are relevant to the topic you choose\n"
     ]
    }
   ],
   "source": [
    "# extract relevant sentences  #search keywords can be a list\n",
    "sel_sentence_sea , sel_sentence_df_sea  = extract_relevant_sentences(cor_dict_sea, ['summer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentences</th>\n",
       "      <th>sha</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rgrp73ca</td>\n",
       "      <td>[' we found that, whilst summer influenza epid...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Increasing similarity in the dynamics of influ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lxff5c9i</td>\n",
       "      <td>[' the results confirm that school term versus...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Parameterizing state–space models for infectio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gkia3rx4</td>\n",
       "      <td>['2 later in the summer, suggesting changes in...</td>\n",
       "      <td>384d87ada46fa690603de7cfbe1286e1d99d6fc9</td>\n",
       "      <td>The effective reproduction number of pandemic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5ji6512w</td>\n",
       "      <td>[' birth weight conditional on gestation lengt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Within-mother analysis of seasonal patterns in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>whtqlu1y</td>\n",
       "      <td>[' in seasonal analysis, human and bovine viru...</td>\n",
       "      <td>742e4f9080c4ff3a0211c8ef20dfb8594b911f69</td>\n",
       "      <td>Hydrologic, land cover, and seasonal patterns ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>t8vmow9s</td>\n",
       "      <td>[' although overall rates of respiratory illne...</td>\n",
       "      <td>2219620e84342b84e1ac0b8cd1e7be4703dd5799</td>\n",
       "      <td>The seasonality of rhinovirus infections and i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>c83xyev5</td>\n",
       "      <td>[' although increased detection of human enter...</td>\n",
       "      <td>d55fd7533a77803778e93b4a2fcd13076f622585</td>\n",
       "      <td>Respiratory viruses are continuously detected ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>zg17f7bd</td>\n",
       "      <td>['abstract influenza a and b, and many unrelat...</td>\n",
       "      <td>68ac63121bded12e1db3178a0c9b050154f81ab8</td>\n",
       "      <td>Seasonality and selective trends in viral acut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6vbhgwsi</td>\n",
       "      <td>[' hpiv-3 was detected at varying levels, but ...</td>\n",
       "      <td>cfeda05ff998d6973560c4f55577a5feaeccb59b</td>\n",
       "      <td>A molecular epidemiological study of human par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>s5c0grz0</td>\n",
       "      <td>[' bacteria were commoner in spring and summer...</td>\n",
       "      <td>e52b14466f05891d49a5ebcdb53b4381f82a0b36</td>\n",
       "      <td>Multiplex PCR reveals that viruses are more fr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          sentences  \\\n",
       "11   rgrp73ca  [' we found that, whilst summer influenza epid...   \n",
       "12   lxff5c9i  [' the results confirm that school term versus...   \n",
       "13   gkia3rx4  ['2 later in the summer, suggesting changes in...   \n",
       "14   5ji6512w  [' birth weight conditional on gestation lengt...   \n",
       "15   whtqlu1y  [' in seasonal analysis, human and bovine viru...   \n",
       "16   t8vmow9s  [' although overall rates of respiratory illne...   \n",
       "17   c83xyev5  [' although increased detection of human enter...   \n",
       "18   zg17f7bd  ['abstract influenza a and b, and many unrelat...   \n",
       "19   6vbhgwsi  [' hpiv-3 was detected at varying levels, but ...   \n",
       "20   s5c0grz0  [' bacteria were commoner in spring and summer...   \n",
       "\n",
       "                                         sha  \\\n",
       "11                                       NaN   \n",
       "12                                       NaN   \n",
       "13  384d87ada46fa690603de7cfbe1286e1d99d6fc9   \n",
       "14                                       NaN   \n",
       "15  742e4f9080c4ff3a0211c8ef20dfb8594b911f69   \n",
       "16  2219620e84342b84e1ac0b8cd1e7be4703dd5799   \n",
       "17  d55fd7533a77803778e93b4a2fcd13076f622585   \n",
       "18  68ac63121bded12e1db3178a0c9b050154f81ab8   \n",
       "19  cfeda05ff998d6973560c4f55577a5feaeccb59b   \n",
       "20  e52b14466f05891d49a5ebcdb53b4381f82a0b36   \n",
       "\n",
       "                                                title  \n",
       "11  Increasing similarity in the dynamics of influ...  \n",
       "12  Parameterizing state–space models for infectio...  \n",
       "13  The effective reproduction number of pandemic ...  \n",
       "14  Within-mother analysis of seasonal patterns in...  \n",
       "15  Hydrologic, land cover, and seasonal patterns ...  \n",
       "16  The seasonality of rhinovirus infections and i...  \n",
       "17  Respiratory viruses are continuously detected ...  \n",
       "18  Seasonality and selective trends in viral acut...  \n",
       "19  A molecular epidemiological study of human par...  \n",
       "20  Multiplex PCR reveals that viruses are more fr...  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_sentence_df_sea.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract keyword search entry and annotate the data for evaluation\n",
    "\n",
    "In this part, we search the data using keywords only, the keyword search will be baseline for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 articles contain keyword ['summer']\n",
      "349 articles contain keyword ['mask']\n",
      "468 articles contain keyword ['incubation', 'day']\n",
      "151 articles contain keyword ['transmission']\n"
     ]
    }
   ],
   "source": [
    "evaluation('seasonality', 'abstract', ['summer'])\n",
    "evaluation('mask', 'abstract', ['mask'])\n",
    "evaluation('incubation', 'abstract', ['incubation','day'])\n",
    "evaluation('asymptomatic', 'abstract', ['transmission'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
